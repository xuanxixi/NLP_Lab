{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xuanxixi/NLP_Lab/blob/main/Lab2_Xi_Xuan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Lab 2024 - LAB2: Morphology\n",
        "In this lab we introduce the topics of morphology and also get some hands on practice.\n",
        "\n",
        "To complete this lab you need to read the material associated to this lab; the following two book chapters (also available in the Moodle, under the `Lab2` tab):\n",
        "\n",
        "- Christine P. Chai (2022).Comparison of text preprocessing methods\n",
        "\n",
        "- Corpus annotation: Hovy, Oxford Handbook of CL, 2nd editionFile (link here)\n",
        "- Text segmentation: Mikheev, Oxford Handbook of CL, 2nd editionFile (ADD link)\n",
        "\n",
        "In this lab we will use Python's popular nltk (Natural Language Toolkit) and matplotlib for visualizations.\n",
        "\n",
        "## **Overview:**\n",
        "\n",
        "Morphology is the study of the structure of words and how they are formed from morphemes, the smallest units of meaning. In Natural Language Processing, understanding morphology is crucial for tasks such as text analysis, machine translation, and sentiment analysis.\n",
        "\n",
        "\n",
        "> _Morphology is the study of the structure of words and how they are formed by combining smaller units of linguistic information called *morphemes*. Historically, most NLP applications, if not all, needed to computationally process the words in a language before any more complex processing could be done --- especially when dealing with morphologically rich languages. After a short overview of basic concepts, to support your readings, in this lab we will present some computational methods to morphology centering in two-level morphology and cascaded-rules_ (Oflazer, Oxford Handbook of CL - edited to match contemporary NLP)\n",
        "\n"
      ],
      "metadata": {
        "id": "ae3FzHn-L_-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 1: Introduction, Definitions and Motivation**\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "1. **Word-form, form**: A concrete word as it occurs in real speech/text -- for computational purposes, for most languages a word is a string of characters separated with spaces in writing (e.g. not always the case for chinese, japanese, etc.)\n",
        "\n",
        "2. **Lemmas**: A distinguished form from a set of morphologically related forms, chosen by convention (e.g., nominative, singular for nouns and infinitive for verbs) to represent that set. E.g., the lemma for “running” is “run.”\n",
        "\n",
        "    - For evey form there is a corresponding lemma. Also called cannonical/base/dictionary/citation form.\n",
        "\n",
        "3. **Lexemes**: An abstract entity, a dictionary word. It can be thought of as a set of word-forms. Every form belongs to one lexeme, referred to by its lemma. E.g., “runs,” “running,” “ran” are form of the same lexeme “run”; \"run\" is traditionally used as the lemma denoting this lexeme.\n",
        "\n",
        "4. **Paradigms**: Sets of related word forms that share a common grammatical function, they all belong to the same lexeme. For example, verb conjugations like “I run,” “he runs,” “we ran.”\n",
        "\n",
        "    **Paradigm of \"insula\"**\n",
        "\n",
        "|Case       | Singular  |  Plural  |\n",
        "|-----------|-----------|----------|\n",
        "|Nominative | insula    |insulae   |\n",
        "|Genitive   | insulae   |insularum |\n",
        "|Dative     |insulae    | insulis  |\n",
        "|Accusative | insulam   |insulas   |\n",
        "|Ablative   | insula    | insulis  |\n",
        "|Vocative   | insula    |insulae   |\n"
      ],
      "metadata": {
        "id": "f6gsA_pZZYUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1. Chai (2022)\n",
        "Based on your understanding of the research article \"Comparison of text prerocessing methods\" answer the followng quesitons.\n",
        "\n",
        "**Q1.** Describe tokenization, stemming, and lemmatization. How do these methods differ in their approach to text preprocessing, and in what situations might each be most beneficial?"
      ],
      "metadata": {
        "id": "t6xKCxfbXsNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "# Tokenization is the process of splitting text into individual units called tokens, which could be words, phrases, or even sentences, depending on the level of tokenization. In word-level tokenization, for instance, a sentence like “I am learning NLP” would be split into tokens: “I,” “am,” “learning,” and “NLP.” Tokenization is essential because most natural language processing (NLP) tasks analyze text at the token level, allowing models to process sequences of meaningful units rather than entire strings of characters.\n",
        "# Best Used When: Tokenization is generally the first step in any text processing pipeline. It’s crucial for all NLP tasks, especially for building vocabularies, training word embeddings, or implementing text analysis tasks where word boundaries need to be defined.\n",
        "\n",
        "# Stemming\n",
        "# Stemming reduces words to their base or root form, known as the stem. This process involves chopping off suffixes or prefixes in a somewhat crude manner. For example, stemming would reduce \"running,\" \"runs,\" and \"runner\" to the root \"run.\" However, stemming doesn’t consider whether the resulting stem is a valid word; it simply removes the common endings based on predefined rules, often leading to non-standard root forms (e.g., \"studies\" becomes \"studi\").\n",
        "# Best Used When: Stemming is useful in applications where exact word forms aren’t as important, such as search engines or information retrieval systems, where retrieving any word form related to the stem is advantageous. It’s also efficient and computationally less intensive.\n",
        "\n",
        "# Lemmatization\n",
        "# Lemmatization, like stemming, reduces words to their base form, known as the lemma. However, unlike stemming, it ensures that the result is an actual word by considering the context and morphological structure of the word. For instance, \"running\" would be lemmatized to \"run,\" and \"better\" would be lemmatized to \"good\" (unlike stemming, which might simply reduce it to \"bett\"). Lemmatization is more accurate but computationally intensive as it requires a vocabulary or dictionary.\n",
        "# Best Used When: Lemmatization is ideal in applications requiring higher precision and linguistic accuracy, such as machine translation, sentiment analysis, or any task where the meaning of words in context is crucial.\n",
        "\n",
        "# Key Differences\n",
        "# Tokenization breaks down text into units.\n",
        "# Stemming reduces words to their stems without ensuring meaningful output.\n",
        "# Lemmatization reduces words to their dictionary base forms, ensuring linguistic accuracy.\n",
        "# Each method has specific strengths. Tokenization is foundational, stemming is fast and effective for broad matches, and lemmatization is accurate but requires more resources. The choice depends on the goals of the NLP task and the balance between accuracy and computational resources."
      ],
      "metadata": {
        "id": "P8HpwQjmXtNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.** Discuss how removing punctuation or stopwords might impact different NLP tasks, such as sentiment analysis or topic modeling. Why might these preprocessing steps enhance certain NLP applications but hinder others?"
      ],
      "metadata": {
        "id": "HCY5TlNpYQkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Punctuation\n",
        "# Sentiment Analysis: In sentiment analysis, punctuation can convey emotional emphasis, especially in social media posts or customer reviews. For instance, exclamation marks (“I love this!”) can amplify positive sentiment, while ellipses or question marks might add nuance or ambiguity (“Really…?”). Removing punctuation in this context might lead to a loss of these subtle cues, potentially reducing the model’s accuracy in interpreting sentiment.\n",
        "\n",
        "# Topic Modeling: In topic modeling, punctuation is generally not informative and can be safely removed to focus on the main content words that define topics. Here, punctuation removal usually enhances performance, helping algorithms like LDA (Latent Dirichlet Allocation) to focus on words and phrases relevant to topic identification without being distracted by extraneous symbols.\n",
        "\n",
        "# Removing Stopwords\n",
        "# Sentiment Analysis: Stopwords are common words like “is,” “and,” or “the,” which often carry minimal semantic weight in determining the sentiment. Removing them can help reduce noise, making it easier for models to focus on sentiment-bearing words (e.g., “happy,” “terrible”). However, some stopwords can add context essential for nuanced sentiment interpretation. For example, “not” in “not good” is crucial for understanding the negative sentiment. Removing it would invert the meaning, so careful handling of negations and certain impactful stopwords is necessary in sentiment analysis.\n",
        "\n",
        "# Topic Modeling: Stopwords generally don’t contribute meaningful information to topic modeling and can dilute the focus on content-specific words. Removing them improves topic coherence by allowing the model to prioritize more significant terms that characterize specific topics. This preprocessing step is usually beneficial in topic modeling, as it reduces dimensionality and helps algorithms find clearer distinctions between topics.\n",
        "\n",
        "# Why These Steps Might Help or Hinder NLP Applications\n",
        "# Enhanced Clarity: In applications like topic modeling, removing punctuation and stopwords refines the focus on content-specific words, reducing noise and improving model efficiency and interpretability.\n",
        "\n",
        "# Loss of Context or Nuance: In sentiment analysis, removing punctuation or important stopwords can strip away nuances that convey emotional tone or modify meaning (e.g., negations like \"not\"). This can lead to misinterpretation, as the context provided by punctuation and certain stopwords is essential to capturing sentiment accurately.\n",
        "\n",
        "# Summary\n",
        "# Helpful: Punctuation and stopword removal typically benefit tasks like topic modeling, where the primary goal is to extract the main ideas without distraction from common words or symbols.\n",
        "# Potentially Detrimental: In tasks such as sentiment analysis, where tone, negation, and subtle emphasis matter, removing these elements can hinder model performance by losing essential contextual or affective information."
      ],
      "metadata": {
        "id": "c0RPD2PbYsUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.** Many fields (e.g., biomedical or legal texts) have specific terminology and formatting. How would you tailor preprocessing for a specialized corpus to avoid data loss while still preparing the text for analysis?"
      ],
      "metadata": {
        "id": "Gyp_H6yMYscc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# When working with specialized corpora, such as biomedical or legal texts, it’s crucial to tailor preprocessing steps to avoid data loss while preparing the text for analysis. Below are tailored strategies to retain domain-specific information.\n",
        "\n",
        "# 1. Custom Stopword Lists\n",
        "# General-purpose stopwords may remove words essential to a specific field. For example:\n",
        "\n",
        "# Biomedical Texts: Words like “dose,” “gene,” or “cell” are critical for understanding content.\n",
        "# Legal Texts: Common legal terms such as “court,” “law,” or “section” hold significant meaning.\n",
        "# Solution: Use a custom stopword list that retains domain-specific terms essential to the field while filtering out other irrelevant common words.\n",
        "\n",
        "# 2. Handling Domain-Specific Terms and Phrases\n",
        "# Technical terms and multi-word phrases are common in specialized fields and should be preserved as single units. For instance:\n",
        "\n",
        "# Biomedical Texts: Multi-word terms like “myocardial infarction” or abbreviations like “COVID-19” must remain intact.\n",
        "# Legal Texts: Terms like “summary judgment” or “burden of proof” should not be split.\n",
        "# Solution: Use domain-aware tokenization to ensure multi-word terms and abbreviations remain as single units.\n",
        "\n",
        "# 3. Entity Recognition and Retention\n",
        "# Named entities in specialized fields, such as chemical compounds or legal citations, are crucial for context and should be preserved.\n",
        "\n",
        "# Biomedical Texts: Entities like drug names, genes, and diseases are vital.\n",
        "# Legal Texts: Case citations, statutes, and legal doctrines should be retained.\n",
        "# Solution: Apply Named Entity Recognition (NER) specific to the domain to identify and preserve important entities.\n",
        "\n",
        "# 4. Custom Lemmatization and Stemming\n",
        "# Unique inflections in specialized terminology may require customized lemmatization or stemming.\n",
        "\n",
        "# Biomedical Texts: Terms like “immunizations” should stem to “immunization” specifically.\n",
        "# Legal Texts: Words like “appeals,” “appealed,” and “appealing” should reduce to “appeal.”\n",
        "# Solution: Use domain-specific lemmatizers or create custom dictionaries that understand relationships between specialized terms.\n",
        "\n",
        "# 5. Punctuation and Formatting Considerations\n",
        "# Punctuation and formatting often convey structure in specialized texts.\n",
        "\n",
        "# Biomedical Texts: Symbols in formulas (e.g., “NaCl”) or p-values are important.\n",
        "# Legal Texts: Section symbols (§) or punctuation in clauses convey legal hierarchy.\n",
        "# Solution: Apply selective punctuation handling, retaining essential symbols and structures.\n",
        "\n",
        "# 6. Context-Sensitive Preprocessing\n",
        "# Words and phrases may have domain-specific meanings.\n",
        "\n",
        "# Biomedical Texts: Terms like “significant” or “control” have specific meanings in experiments.\n",
        "# Legal Texts: Words like “party” or “interest” hold unique legal interpretations.\n",
        "# Solution: Use domain-specific glossaries or embeddings to capture terms’ precise meanings within their field context."
      ],
      "metadata": {
        "id": "KauON62jYzUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.** With the advancement of pre-trained language models like BERT, why is text preprocessing still considered necessary? What preprocessing steps are crucial for leveraging these models, and how might excessive or inadequate preprocessing affect model performance?"
      ],
      "metadata": {
        "id": "g9XYXHSsY2ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Why Text Preprocessing is Still Necessary with Pre-trained Language Models like BERT\n",
        "\n",
        "# Pre-trained language models like BERT have significantly advanced NLP by providing deep contextual embeddings and handling a wide range of linguistic variations. However, preprocessing remains essential to optimize performance and ensure that these models are trained and fine-tuned on clean, relevant data. Preprocessing helps standardize input, reduce noise, and improve the efficiency of model training and inference, all of which are critical for maximizing the model's potential.\n",
        "\n",
        "# Crucial Preprocessing Steps for Leveraging Pre-trained Models\n",
        "# Tokenization: Models like BERT use subword tokenization (e.g., WordPiece), which breaks down words into meaningful subword units. Proper tokenization is crucial for BERT to handle variations, rare words, and morphology without losing semantic meaning. Adhering to the specific tokenization scheme of the model ensures that input is compatible and maximizes the information captured in embeddings.\n",
        "\n",
        "# Lowercasing (Optional): For models that are cased, maintaining capitalization is important as it preserves information (e.g., \"Apple\" vs. \"apple\"). For uncased models, lowercasing can help reduce data sparsity and standardize text, ensuring that words like \"Dog\" and \"dog\" are treated as identical tokens.\n",
        "\n",
        "# Handling Special Characters and Punctuation: While BERT can manage many special characters, it’s helpful to remove irrelevant symbols and punctuation that might introduce noise. However, relevant punctuation should be retained, especially in tasks sensitive to tone or structure, like sentiment analysis.\n",
        "\n",
        "# Stopword Removal (Optional): Depending on the task, stopwords may be retained to preserve context (e.g., “not” in “not good” is essential for sentiment). In tasks where stopwords don’t add value, removing them can simplify inputs and focus the model on meaningful content words.\n",
        "\n",
        "# Dealing with Rare Symbols or Non-Standard Text: Certain symbols or non-standard text (e.g., emojis, URLs) may need special handling. For tasks where these elements carry meaning, they can be converted to placeholders or tokens recognized by the model. For example, in social media analysis, emojis may provide sentiment information and should be handled accordingly.\n",
        "\n",
        "# Impact of Excessive or Inadequate Preprocessing\n",
        "# Excessive Preprocessing: Over-cleaning can strip valuable information from the text, reducing the model’s ability to capture nuances or context. For example, excessive removal of punctuation or stopwords might hinder tasks like sentiment analysis, where tone and negation are crucial. Removing uncommon words or symbols can also affect the model’s handling of rare or domain-specific terms, leading to loss of specificity in outputs.\n",
        "\n",
        "# Inadequate Preprocessing: Insufficient preprocessing might leave noise in the data, such as typos, inconsistent capitalization, or irrelevant symbols. This can cause the model to focus on unimportant details, leading to less effective embeddings and a higher risk of overfitting to irrelevant features. For instance, failing to standardize spelling or ignore irrelevant characters might lead to inconsistent tokenization, resulting in a fragmented understanding of similar words.\n",
        "\n",
        "# Summary\n",
        "# Even with advanced language models, preprocessing remains a crucial step for data consistency, clarity, and relevance. Proper preprocessing allows BERT and similar models to make the most of the linguistic information present, leading to improved performance and generalization across NLP tasks."
      ],
      "metadata": {
        "id": "h_u_66hrY1Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2: WordNet\n",
        "\n",
        "We will use **WordNet**. It is a lexical database for the English language, developed to model the way humans understand words and their relationships. Created at Princeton University, it organizes words into sets of synonyms called synsets, each representing a unique concept or meaning. Synsets are linked through various types of relationships, such as:\n",
        "\n",
        "- Synonymy: Words with similar meanings (e.g., car and automobile).\n",
        "- Antonymy: Words with opposite meanings (e.g., hot and cold).\n",
        "- Hypernymy/Hyponymy: \"Is a type of\" relationships (e.g., dog is a type of animal).\n",
        "- Meronymy/Holonymy: Part-to-whole relationships (e.g., wheel is part of a car).\n",
        "\n",
        "WordNet is a valuable tool in NLP and computational linguistics for tasks like word sense disambiguation, semantic similarity measurement, and information retrieval. It’s often used in applications such as chatbots, sentiment analysis, and machine translation to enhance understanding of word meanings and context.\n",
        "\n"
      ],
      "metadata": {
        "id": "DBbm7qRdaiMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download WordNet data\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrd6k2_rakRr",
        "outputId": "bbe3461d-59f8-407b-c5e4-ae9af0876f3c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lemmatization and word forms identification\n",
        "Let's use the lemmatizer to identify word forms and their lemmas.\n",
        "\n"
      ],
      "metadata": {
        "id": "8-c8s9Vbam9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Define a list of word forms\n",
        "word_forms = ['running', 'ran', 'better', 'cats', 'playing']\n",
        "\n",
        "# Create a function to get lemmas\n",
        "def get_lemmas(words):\n",
        "    return [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "# Get lemmas for the word forms\n",
        "lemmas = get_lemmas(word_forms)\n",
        "print(\"Word Forms: \", word_forms)\n",
        "print(\"Lemmas: \", lemmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_Qn7nXDbJTE",
        "outputId": "1f698bf1-e4fd-4bcc-f34d-a7759486b4b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Forms:  ['running', 'ran', 'better', 'cats', 'playing']\n",
            "Lemmas:  ['running', 'ran', 'better', 'cat', 'playing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Free- andbound-morphemes\n",
        "We can also use it to distinguish between free and bound morphemes."
      ],
      "metadata": {
        "id": "8_kT0YFBb-po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of words\n",
        "words = ['cats', 'running', 'unhappiness', 'book', 'toothbrush']\n",
        "\n",
        "# Function to identify free and bound morphemes\n",
        "def identify_morphemes(word_list):\n",
        "    free_morphemes = []\n",
        "    bound_morphemes = []\n",
        "\n",
        "    for word in word_list:\n",
        "        if word in ['cat', 'run', 'happy', 'book', 'tooth', 'brush']:\n",
        "            free_morphemes.append(word)\n",
        "        else:\n",
        "            # Identify bound morphemes\n",
        "            if word.endswith('s'):\n",
        "                bound_morphemes.append('s (plural)')\n",
        "            if word.startswith('un'):\n",
        "                bound_morphemes.append('un (negative)')\n",
        "            if 'ness' in word:\n",
        "                bound_morphemes.append('ness (noun suffix)')\n",
        "\n",
        "    return free_morphemes, bound_morphemes\n",
        "\n",
        "free, bound = identify_morphemes(words)\n",
        "print(\"Free Morphemes: \", free)\n",
        "print(\"Bound Morphemes: \", bound)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKYUJ0o-bOM9",
        "outputId": "2ae96e42-f236-4f05-fad6-dd16f734af5e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free Morphemes:  ['book']\n",
            "Bound Morphemes:  ['s (plural)', 's (plural)', 'un (negative)', 'ness (noun suffix)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.** Enhance the existing morpheme identification code to:\n",
        "\n",
        "1. Identify more free morphemes.\n",
        "2. Categorize additional bound morphemes such as prefixes and suffixes.\n",
        "3. Handle new words and recognize different types of morphemes.\n",
        "\n",
        "*How to get started*\n",
        "1. Review the Existing Code: Understand how the current identify_morphemes function works.\n",
        "\n",
        "2. Extend the Free Morphemes List: Add at least five more free morphemes to the list that the function should recognize.\n",
        "\n",
        "3. Add New Bound Morphemes: Extend the identification of bound morphemes to include:\n",
        "    - Prefixes like \"re-\" (e.g., \"redo\")\n",
        "    - Suffixes like \"-able\" (e.g., \"readable\") and \"-ing\" (e.g., \"running\")\n",
        "    - Create New Words: Add a new list of words that includes various combinations of free and bound morphemes. For example:\n",
        "\n",
        "    `words = ['redo', 'reading', 'happiness', 'bookshelf', 'unhappy', 'toothpaste', 'quickly']`\n",
        "\n",
        "4. Adjust the `identify_morphemes` function to recognize the new free morphemes and bound morphemes you've added.\n",
        "\n",
        "5. Test the Function: Run the modified function and print out the identified free and bound morphemes.\n"
      ],
      "metadata": {
        "id": "Vo9zf_8Ac2e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of free and bound morphemes\n",
        "free_morphemes = ['book', 'read', 'run', 'happy', 'tooth', 'quick', 'love', 'shelf', 'paste', 'time']\n",
        "prefixes = ['re', 'un', 'dis']\n",
        "suffixes = ['able', 'ing', 'ness', 'ly', 's', 'ed']\n",
        "\n",
        "# Sample words to test the morpheme identification\n",
        "words = ['redo', 'reading', 'happiness', 'bookshelf', 'unhappy', 'toothpaste', 'quickly', 'timely', 'loved']\n",
        "\n",
        "def identify_morphemes(word):\n",
        "    morphemes = {\n",
        "        'free_morphemes': [],\n",
        "        'prefixes': [],\n",
        "        'suffixes': []\n",
        "    }\n",
        "\n",
        "    # Check for prefixes\n",
        "    for prefix in prefixes:\n",
        "        if word.startswith(prefix):\n",
        "            morphemes['prefixes'].append(prefix)\n",
        "            word = word[len(prefix):]  # Remove prefix for further analysis\n",
        "            break  # Only consider the first matching prefix\n",
        "\n",
        "    # Check for suffixes\n",
        "    for suffix in suffixes:\n",
        "        if word.endswith(suffix):\n",
        "            morphemes['suffixes'].append(suffix)\n",
        "            word = word[:-len(suffix)]  # Remove suffix for further analysis\n",
        "            break  # Only consider the first matching suffix\n",
        "\n",
        "    # Identify any free morphemes within the remaining part of the word\n",
        "    for free_morpheme in free_morphemes:\n",
        "        if free_morpheme in word:\n",
        "            morphemes['free_morphemes'].append(free_morpheme)\n",
        "            word = word.replace(free_morpheme, '', 1)  # Remove matched free morpheme\n",
        "\n",
        "    # If any part of the word is left, consider it as unidentified morpheme for improvement\n",
        "    if word:\n",
        "        morphemes['unidentified'] = word\n",
        "\n",
        "    return morphemes\n",
        "\n",
        "# Test the function\n",
        "for word in words:\n",
        "    result = identify_morphemes(word)\n",
        "    print(f\"Word: {word}\")\n",
        "    print(\"Identified morphemes:\")\n",
        "    print(f\"  Free Morphemes: {result['free_morphemes']}\")\n",
        "    print(f\"  Prefixes: {result['prefixes']}\")\n",
        "    print(f\"  Suffixes: {result['suffixes']}\")\n",
        "    if 'unidentified' in result:\n",
        "        print(f\"  Unidentified Morpheme: {result['unidentified']}\")\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "id": "70ZLRBZydfOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4325d0f8-201f-4f54-ab9c-596426c63b09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: redo\n",
            "Identified morphemes:\n",
            "  Free Morphemes: []\n",
            "  Prefixes: ['re']\n",
            "  Suffixes: []\n",
            "  Unidentified Morpheme: do\n",
            "------------------------------\n",
            "Word: reading\n",
            "Identified morphemes:\n",
            "  Free Morphemes: []\n",
            "  Prefixes: ['re']\n",
            "  Suffixes: ['ing']\n",
            "  Unidentified Morpheme: ad\n",
            "------------------------------\n",
            "Word: happiness\n",
            "Identified morphemes:\n",
            "  Free Morphemes: []\n",
            "  Prefixes: []\n",
            "  Suffixes: ['ness']\n",
            "  Unidentified Morpheme: happi\n",
            "------------------------------\n",
            "Word: bookshelf\n",
            "Identified morphemes:\n",
            "  Free Morphemes: ['book', 'shelf']\n",
            "  Prefixes: []\n",
            "  Suffixes: []\n",
            "------------------------------\n",
            "Word: unhappy\n",
            "Identified morphemes:\n",
            "  Free Morphemes: ['happy']\n",
            "  Prefixes: ['un']\n",
            "  Suffixes: []\n",
            "------------------------------\n",
            "Word: toothpaste\n",
            "Identified morphemes:\n",
            "  Free Morphemes: ['tooth', 'paste']\n",
            "  Prefixes: []\n",
            "  Suffixes: []\n",
            "------------------------------\n",
            "Word: quickly\n",
            "Identified morphemes:\n",
            "  Free Morphemes: ['quick']\n",
            "  Prefixes: []\n",
            "  Suffixes: ['ly']\n",
            "------------------------------\n",
            "Word: timely\n",
            "Identified morphemes:\n",
            "  Free Morphemes: ['time']\n",
            "  Prefixes: []\n",
            "  Suffixes: ['ly']\n",
            "------------------------------\n",
            "Word: loved\n",
            "Identified morphemes:\n",
            "  Free Morphemes: []\n",
            "  Prefixes: []\n",
            "  Suffixes: ['ed']\n",
            "  Unidentified Morpheme: lov\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Disambiguation & ambiguities\n",
        "We can create compound words from free morphemes."
      ],
      "metadata": {
        "id": "I7BqIXtue1fZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two lists of free morphemes\n",
        "nouns = ['tooth', 'note', 'book']\n",
        "verbs = ['brush', 'write', 'read']\n",
        "\n",
        "# Function to create compounds\n",
        "def create_compounds(nouns, verbs):\n",
        "    compounds = [noun + verb for noun in nouns for verb in verbs]\n",
        "    return compounds\n",
        "\n",
        "compounds = create_compounds(nouns, verbs)\n",
        "print(\"Compound Words: \", compounds)"
      ],
      "metadata": {
        "id": "jT8OGpBNe98X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9145615d-2964-42c6-d43d-ec46c23f8b1a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compound Words:  ['toothbrush', 'toothwrite', 'toothread', 'notebrush', 'notewrite', 'noteread', 'bookbrush', 'bookwrite', 'bookread']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use `nltk` to resolve ambiguities"
      ],
      "metadata": {
        "id": "Q_PbevA-fIP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download WordNet if not already downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Function to resolve ambiguities\n",
        "def resolve_ambiguities(word):\n",
        "    synsets = wordnet.synsets(word)\n",
        "    return [(synset.name(), synset.definition()) for synset in synsets]\n",
        "\n",
        "# Example ambiguous words\n",
        "ambiguous_words = ['bark', 'lead', 'bat']\n",
        "\n",
        "for word in ambiguous_words:\n",
        "    meanings = resolve_ambiguities(word)\n",
        "    print(f\"\\nAmbiguous Word: {word}\")\n",
        "    for meaning in meanings:\n",
        "        print(f\"Synset: {meaning[0]} - Definition: {meaning[1]}\")\n"
      ],
      "metadata": {
        "id": "o7NwHEZOfYtt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0bbad0-41c5-42f7-edff-d97c51e20fe6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ambiguous Word: bark\n",
            "Synset: bark.n.01 - Definition: tough protective covering of the woody stems and roots of trees and other woody plants\n",
            "Synset: bark.n.02 - Definition: a noise resembling the bark of a dog\n",
            "Synset: bark.n.03 - Definition: a sailing ship with 3 (or more) masts\n",
            "Synset: bark.n.04 - Definition: the sound made by a dog\n",
            "Synset: bark.v.01 - Definition: speak in an unfriendly tone\n",
            "Synset: bark.v.02 - Definition: cover with bark\n",
            "Synset: bark.v.03 - Definition: remove the bark of a tree\n",
            "Synset: bark.v.04 - Definition: make barking sounds\n",
            "Synset: bark.v.05 - Definition: tan (a skin) with bark tannins\n",
            "\n",
            "Ambiguous Word: lead\n",
            "Synset: lead.n.01 - Definition: an advantage held by a competitor in a race\n",
            "Synset: lead.n.02 - Definition: a soft heavy toxic malleable metallic element; bluish white when freshly cut but tarnishes readily to dull grey\n",
            "Synset: lead.n.03 - Definition: evidence pointing to a possible solution\n",
            "Synset: lead.n.04 - Definition: a position of leadership (especially in the phrase `take the lead')\n",
            "Synset: lead.n.05 - Definition: the angle between the direction a gun is aimed and the position of a moving target (correcting for the flight time of the missile)\n",
            "Synset: lead.n.06 - Definition: the introductory section of a story\n",
            "Synset: lead.n.07 - Definition: (sports) the score by which a team or individual is winning\n",
            "Synset: star.n.04 - Definition: an actor who plays a principal role\n",
            "Synset: lead.n.09 - Definition: (baseball) the position taken by a base runner preparing to advance to the next base\n",
            "Synset: tip.n.03 - Definition: an indication of potential opportunity\n",
            "Synset: lead.n.11 - Definition: a news story of major importance\n",
            "Synset: spark_advance.n.01 - Definition: the timing of ignition relative to the position of the piston in an internal-combustion engine\n",
            "Synset: leash.n.01 - Definition: restraint consisting of a rope (or light chain) used to restrain an animal\n",
            "Synset: lead.n.14 - Definition: thin strip of metal used to separate lines of type in printing\n",
            "Synset: lead.n.15 - Definition: mixture of graphite with clay in different degrees of hardness; the marking substance in a pencil\n",
            "Synset: jumper_cable.n.01 - Definition: a jumper that consists of a short piece of wire\n",
            "Synset: lead.n.17 - Definition: the playing of a card to start a trick in bridge\n",
            "Synset: lead.v.01 - Definition: take somebody somewhere\n",
            "Synset: leave.v.07 - Definition: have as a result or residue\n",
            "Synset: lead.v.03 - Definition: tend to or result in\n",
            "Synset: lead.v.04 - Definition: travel in front of; go in advance of others\n",
            "Synset: lead.v.05 - Definition: cause to undertake a certain action\n",
            "Synset: run.v.03 - Definition: stretch out over a distance, space, time, or scope; run or extend between two points or beyond a certain point\n",
            "Synset: head.v.02 - Definition: be in charge of\n",
            "Synset: lead.v.08 - Definition: be ahead of others; be the first\n",
            "Synset: contribute.v.03 - Definition: be conducive to\n",
            "Synset: conduct.v.02 - Definition: lead, as in the performance of a composition\n",
            "Synset: go.v.25 - Definition: lead, extend, or afford access\n",
            "Synset: precede.v.04 - Definition: move ahead (of others) in time or space\n",
            "Synset: run.v.23 - Definition: cause something to pass or lead somewhere\n",
            "Synset: moderate.v.01 - Definition: preside over\n",
            "\n",
            "Ambiguous Word: bat\n",
            "Synset: bat.n.01 - Definition: nocturnal mouselike mammal with forelimbs modified to form membranous wings and anatomical adaptations for echolocation by which they navigate\n",
            "Synset: bat.n.02 - Definition: (baseball) a turn trying to get a hit\n",
            "Synset: squash_racket.n.01 - Definition: a small racket with a long handle used for playing squash\n",
            "Synset: cricket_bat.n.01 - Definition: the club used in playing cricket\n",
            "Synset: bat.n.05 - Definition: a club used for hitting a ball in various games\n",
            "Synset: bat.v.01 - Definition: strike with, or as if with a baseball bat\n",
            "Synset: bat.v.02 - Definition: wink briefly\n",
            "Synset: bat.v.03 - Definition: have a turn at bat\n",
            "Synset: bat.v.04 - Definition: use a bat\n",
            "Synset: cream.v.02 - Definition: beat thoroughly and conclusively in a competition or fight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.** Create compound words from given lists of free morphemes (nouns and verbs) and resolve ambiguities in the compound words generated by checking their meanings using WordNet.\n",
        "\n",
        "*How to get started*\n",
        "1. Start by understanding the provided code snippets above.\n",
        "\n",
        "2. Define New Morphemes by expanding the existing lists of nouns and verbs to include at least three more words in each category.\n",
        "\n",
        "3. Use a function to create compound words from the updated lists of nouns and verbs.\n",
        "\n",
        "4. Resolve Ambiguities: For each compound word generated, use the WordNet library to check for ambiguities and print out their meanings.\n",
        "\n",
        "Output the Results: Display the compound words and their corresponding meanings.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qip0RB3lf9e-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "import nltk\n",
        "\n",
        "# 下载WordNet数据（如果还没有下载的话）\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# 定义扩展后的自由词素列表（名词）\n",
        "nouns = ['book', 'shelf', 'tooth', 'paste', 'time', 'house', 'light', 'life', 'work', 'school']\n",
        "\n",
        "# 函数：生成名词-名词复合词\n",
        "def create_compound_words(nouns):\n",
        "    compound_words = []\n",
        "\n",
        "    # 使用双重循环生成“名词-名词”复合词组合\n",
        "    for noun1 in nouns:\n",
        "        for noun2 in nouns:\n",
        "            if noun1 != noun2:  # 避免生成重复的单词组合，如“bookbook”\n",
        "                compound_words.append(noun1 + noun2)\n",
        "\n",
        "    return compound_words\n",
        "\n",
        "# 函数：使用WordNet解析复合词的含义\n",
        "def get_meanings(word):\n",
        "    synsets = wn.synsets(word)\n",
        "    meanings = []\n",
        "\n",
        "    # 获取该词的所有定义\n",
        "    for syn in synsets:\n",
        "        meanings.append(syn.definition())\n",
        "\n",
        "    # 处理多义词情况\n",
        "    if len(meanings) > 1:\n",
        "        print(f\"**Ambiguous Word: {word}**\")\n",
        "        print(\"Possible meanings:\")\n",
        "        for meaning in meanings:\n",
        "            print(f\"  - {meaning}\")\n",
        "    elif meanings:\n",
        "        print(f\"Word: {word}\")\n",
        "        print(f\"Meaning: {meanings[0]}\")\n",
        "    else:\n",
        "        print(f\"Word: {word} - No meaning found in WordNet\")\n",
        "\n",
        "# 生成复合词并输出其含义\n",
        "compound_words = create_compound_words(nouns)\n",
        "for compound_word in compound_words:\n",
        "    get_meanings(compound_word)\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "id": "8alHOhdFgGYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1fd4394-7e23-43aa-b3c5-43d6c873f7dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: bookshelf\n",
            "Meaning: a shelf on which to keep books\n",
            "------------------------------\n",
            "Word: booktooth - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: bookpaste - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: booktime - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: bookhouse - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: booklight - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: booklife - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: bookwork - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: bookschool - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: shelfbook - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: shelftooth - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: shelfpaste - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: shelftime - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: shelfhouse - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: shelflight - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: shelflife - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: shelfwork - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: shelfschool - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: toothbook - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: toothshelf - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: toothpaste\n",
            "Meaning: a dentifrice in the form of a paste\n",
            "------------------------------\n",
            "Word: toothtime - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: toothhouse - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: toothlight - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: toothlife - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: toothwork - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: toothschool - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: pastebook - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: pasteshelf - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: pastetooth - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: pastetime - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: pastehouse - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: pastelight - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: pastelife - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: pastework - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: pasteschool - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: timebook - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: timeshelf - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: timetooth - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: timepaste - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: timehouse - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: timelight - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: timelife - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: timework\n",
            "Meaning: work paid for at a rate per unit of time\n",
            "------------------------------\n",
            "Word: timeschool - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: housebook - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: houseshelf - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: housetooth - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: housepaste - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: housetime - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: houselight - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: houselife - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: housework\n",
            "Meaning: the work of cleaning and running a house\n",
            "------------------------------\n",
            "Word: houseschool - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lightbook - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lightshelf - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lighttooth - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lightpaste - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lighttime - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lighthouse\n",
            "Meaning: a tower with a light that gives warning of shoals to passing ships\n",
            "------------------------------\n",
            "Word: lightlife - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lightwork - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lightschool - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lifebook - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lifeshelf - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lifetooth - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lifepaste - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lifetime\n",
            "Meaning: the period during which something is functional (as between birth and death)\n",
            "------------------------------\n",
            "Word: lifehouse - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lifelight - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: lifework\n",
            "Meaning: the principal work of your career\n",
            "------------------------------\n",
            "Word: lifeschool - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: workbook\n",
            "Meaning: a student's book or booklet containing problems with spaces for solving them\n",
            "------------------------------\n",
            "Word: workshelf - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: worktooth - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: workpaste - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: worktime - No meaning found in WordNet\n",
            "------------------------------\n",
            "**Ambiguous Word: workhouse**\n",
            "Possible meanings:\n",
            "  - a poorhouse where able-bodied poor are compelled to labor\n",
            "  - a county jail that holds prisoners for periods up to 18 months\n",
            "------------------------------\n",
            "Word: worklight - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: worklife - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: workschool - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: schoolbook\n",
            "Meaning: a book prepared for use in schools or colleges\n",
            "------------------------------\n",
            "Word: schoolshelf - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: schooltooth - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: schoolpaste - No meaning found in WordNet\n",
            "------------------------------\n",
            "**Ambiguous Word: schooltime**\n",
            "Possible meanings:\n",
            "  - the period of instruction in a school; the time period when school is in session\n",
            "  - the time of life when you are going to school\n",
            "------------------------------\n",
            "Word: schoolhouse\n",
            "Meaning: a building where young people receive education\n",
            "------------------------------\n",
            "Word: schoollight - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: schoollife - No meaning found in WordNet\n",
            "------------------------------\n",
            "Word: schoolwork\n",
            "Meaning: a school task performed by a student to satisfy the teacher\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.** Reflection: Write a brief paragraph discussing the most interesting compound word generated and any challenges faced while using WordNet."
      ],
      "metadata": {
        "id": "kK6Fa2MrhZTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the most interesting compound words generated was **\"bookshelf\"**. This compound word is intuitively recognizable, and WordNet identifies it as a \"a piece of furniture with shelves for storing books,\" which aligns well with the real-world understanding of the term. The challenge with WordNet, however, emerged when attempting to identify less conventional compound words or those not as widely used in English. For example, combinations like **\"toothpaste\"** were easily recognized, while other creative compounds such as **\"timehouse\"** or **\"lifepaste\"** had no definitions. This limitation highlights that while WordNet is powerful for established vocabulary, it may not fully capture newer or less conventional compound formations. Additionally, handling ambiguities required careful interpretation to understand which definition best fit the compound context, especially for words with multiple meanings, such as **\"lightwork\"**, which could have various interpretations depending on the context."
      ],
      "metadata": {
        "id": "ygZPEvqvho-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3: Pirrelli (2019)\n",
        "Based on Pirelli (2019)'s text \"Morphological Theory and Computational Linguistics\", answer the following questions:\n",
        "\n",
        "**Q1.** The text discusses different computational models, such as finite-state automata (FSA) and neural networks, in lexical processing. Describe these models' roles and explain how they contribute to word processing in computational morphology."
      ],
      "metadata": {
        "id": "yU5miLNamIrA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Pirelli's (2019) \"Morphological Theory and Computational Linguistics,\" finite-state automata (FSA) and neural networks are presented as foundational computational models in lexical processing, each contributing to computational morphology in unique ways.\n",
        "\n",
        "### Finite-State Automata (FSA)\n",
        "\n",
        "FSAs are rule-based models that operate by traversing states based on input symbols, making them particularly suitable for languages with regular morphological patterns. In computational morphology, FSAs are used to model word formation and recognition by defining permissible sequences of morphemes. For example, FSAs can process affixation rules, such as prefixes and suffixes, allowing them to efficiently generate and recognize word forms. Their deterministic nature makes FSAs ideal for processing predictable language patterns, such as concatenative morphology, where morphemes are added linearly. This model is especially useful in languages with clear-cut morphological boundaries and limited inflectional complexity.\n",
        "\n",
        "### Neural Networks\n",
        "\n",
        "Neural networks, by contrast, offer a data-driven approach to lexical processing. Rather than relying on predefined rules, neural networks learn morphological patterns from large datasets, making them powerful for handling irregular or complex morphological structures that FSAs may struggle with. In computational morphology, neural networks contribute to word processing by identifying non-linear and contextual morphological transformations, such as in non-concatenative morphology (e.g., root-and-pattern morphology in Semitic languages) or in tasks involving ambiguous or irregular inflections. Neural networks excel in capturing dependencies across morphemes, enabling them to process complex morphological features in a more flexible manner than FSAs.\n",
        "\n",
        "### Contributions to Word Processing\n",
        "\n",
        "Both models enhance word processing capabilities in computational morphology. FSAs provide efficient, rule-based pattern recognition for predictable morpheme sequences, whereas neural networks offer the adaptability to handle complex and irregular morphological variations through learning. Together, these models enable robust, comprehensive morphological analysis, balancing efficiency with the flexibility to accommodate linguistic complexity."
      ],
      "metadata": {
        "id": "vaUBey3Qh0Yd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.** How does a Finite State Automaton operate in morphological analysis, and what limitations might it face in handling complex morphological structures?"
      ],
      "metadata": {
        "id": "DDqNPAmpm28Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Finite State Automaton (FSA) operates in morphological analysis by sequentially processing strings of input symbols (such as characters or morphemes) according to predefined states and transitions. Each state represents a specific stage in recognizing or constructing a word form, and transitions between states are triggered by input symbols that match morphological rules. For example, an FSA can process a sequence of morphemes, like a root followed by a suffix, to recognize or generate valid word forms, as in adding \"-ed\" to regular verbs in English to form past tense (e.g., \"walk\" to \"walked\"). FSAs are efficient at handling concatenative morphological processes, where morphemes are added linearly, and they are widely used for regular morphological structures in language.\n",
        "\n",
        "### Limitations of FSAs in Handling Complex Morphological Structures\n",
        "\n",
        "While FSAs are effective for languages with predictable, linear morphology, they face limitations when dealing with complex morphological structures, particularly:\n",
        "\n",
        "1. **Non-Concatenative Morphology**: FSAs struggle with non-concatenative morphology, where morphological transformations do not involve linear additions. For instance, root-and-pattern morphology, common in Semitic languages like Arabic, involves modifying internal parts of a root word (e.g., changing vowel patterns within the root consonants). FSAs, by their nature, cannot easily model such non-linear transformations.\n",
        "\n",
        "2. **Irregular Morphology and Exceptions**: FSAs rely on deterministic rules, making it challenging to handle irregular morphological forms and exceptions, such as irregular verb conjugations in English (e.g., “go” to “went”). Encoding numerous exceptions increases the complexity of the FSA and can make it inefficient.\n",
        "\n",
        "3. **Morphological Ambiguity**: In languages with high morphological ambiguity, a single word form can map to multiple morphological analyses or interpretations (e.g., polysemous or homonymous forms). FSAs have limited capacity to handle such ambiguity, as they operate on predefined transitions without the contextual flexibility needed to distinguish between different interpretations.\n",
        "\n",
        "4. **Dependency on Contextual Information**: FSAs generally process symbols without considering broader linguistic context, which limits their ability to analyze morphological forms influenced by syntactic or semantic context. For example, an FSA may struggle to correctly process cases where morphology changes based on sentence structure or word meaning.\n",
        "\n",
        "In summary, while FSAs provide a structured, rule-based approach to morphological analysis, they are best suited to languages with regular, concatenative morphology. Their limitations in handling non-linear transformations, irregular forms, and context-sensitive morphology often require alternative models, such as neural networks, for more complex morphological structures."
      ],
      "metadata": {
        "id": "4Ia73m5xiAg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.** The chapter highlights issues with stem allomorphy in languages like Italian. What is stem allomorphy, and how does computational morphology attempt to generalize across different forms?\n"
      ],
      "metadata": {
        "id": "sqHP8UV3nDOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stem allomorphy** refers to the phenomenon where a word’s root or stem takes on different forms, often due to phonological, morphological, or syntactic rules. In languages like Italian, this is common, as certain stems undergo changes depending on grammatical features such as tense, mood, or number. For example, in Italian, the verb \"fare\" (to do/make) has multiple stem forms like *facci-* (in \"facciamo\" – \"we do/make\") and *facc-* (in \"faccio\" – \"I do/make\"). These variations, or allomorphs, pose challenges for computational morphology, as different surface forms must be recognized as belonging to the same underlying lexeme.\n",
        "\n",
        "### Generalizing Across Allomorphic Forms in Computational Morphology\n",
        "\n",
        "In computational morphology, handling stem allomorphy requires creating models that can generalize across these varying stem forms to recognize them as representations of a single lexeme. Several approaches are commonly used:\n",
        "\n",
        "1. **Lexicon-Based Approaches with Allomorphic Rules**: One approach is to store each allomorphic form in a lexicon alongside rules that specify the contexts in which each form appears. For example, rules might dictate that the stem *facci-* is used in plural forms of the subjunctive, while *facc-* appears in the first person singular. This approach works well for predictable, rule-governed allomorphy, though it can become complex for languages with extensive or irregular allomorphy.\n",
        "\n",
        "2. **Finite-State Transducers (FSTs)**: Finite-State Transducers, an extension of FSAs, are often used to handle regular allomorphy by transforming one form into another based on specified conditions. FSTs can map different allomorphic forms to a common underlying representation by defining transitions that apply transformations when certain morphological conditions are met (e.g., tense or person). While effective for regular allomorphy, FSTs face limitations with highly irregular patterns or when the allomorphy is influenced by non-linear, non-concatenative processes.\n",
        "\n",
        "3. **Machine Learning Models and Neural Networks**: For more irregular or less predictable cases of allomorphy, data-driven approaches, especially neural networks, can learn to associate different allomorphic forms with the same underlying lexeme based on context. These models can generalize across observed forms without explicitly defined rules, making them more adaptable to irregular patterns of allomorphy. Neural networks trained on large morphological datasets can learn to infer and generalize patterns, handling forms that would otherwise require numerous exceptions.\n",
        "\n",
        "4. **Abstract Morphological Representations**: Some computational models employ abstract representations that link different allomorphic forms to a single abstract root or base form. By recognizing shared morphological or phonological features across forms, these models can treat *facci-* and *facc-* as variants of the same root, thereby reducing the complexity of mapping surface forms to their underlying lexical entries.\n",
        "\n",
        "### Summary\n",
        "\n",
        "In essence, computational morphology tackles stem allomorphy by employing rule-based or data-driven methods to map diverse stem forms back to a unified lexeme. While rule-based approaches work well for predictable patterns, more flexible neural approaches are increasingly essential for generalizing across irregular allomorphic forms, especially in languages with extensive morphological variation. These methods enable systems to manage linguistic complexity while maintaining accurate lexical representations across diverse morphological contexts."
      ],
      "metadata": {
        "id": "lOHR300miMey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.** Discuss the role of supervised and unsupervised learning methods in morphological induction. What are some specific examples of machine learning techniques used in morphology?"
      ],
      "metadata": {
        "id": "-drA0MeQnxti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In morphological induction—the task of discovering morphological patterns and structures in language data—both supervised and unsupervised learning methods play important roles. These methods help computational systems identify, generate, and analyze morphemes, stems, affixes, and their combinations in word formation, even in languages with complex morphology.\n",
        "\n",
        "### Supervised Learning in Morphological Induction\n",
        "\n",
        "Supervised learning involves training a model on labeled data, where words are annotated with their morphological features (such as roots, prefixes, suffixes, and grammatical categories). This method is highly effective when labeled morphological datasets are available and can be used to build systems with high accuracy in morphological analysis, segmentation, and generation.\n",
        "\n",
        "- **Role in Morphology**: Supervised learning is used to train models for tasks such as morphological tagging (e.g., identifying tense, number, and gender in words), morphological segmentation (e.g., splitting words into morphemes), and lemmatization (e.g., reducing words to their base forms). By learning from labeled data, supervised models can generalize morphological rules and exceptions more effectively.\n",
        "\n",
        "- **Examples**:\n",
        "  - **Conditional Random Fields (CRFs)**: CRFs are commonly used in supervised morphological tagging and segmentation. For example, they can be trained to label segments of words based on morpheme boundaries and to identify specific morpheme types, such as prefixes and suffixes, in complex words.\n",
        "  - **Sequence-to-Sequence Models**: Models like Recurrent Neural Networks (RNNs) and Transformers are used to predict morphological transformations, such as converting a verb to its past tense form or changing nouns from singular to plural. For instance, an RNN might be trained to transform \"run\" into \"running\" or \"go\" into \"went\" by learning morphological rules from labeled data.\n",
        "\n",
        "### Unsupervised Learning in Morphological Induction\n",
        "\n",
        "Unsupervised learning, by contrast, is used when labeled morphological data is not available. In these cases, models must automatically discover patterns in the data, such as common prefixes, suffixes, and root forms, without explicit annotations. This is particularly useful for low-resource languages where morphological annotations are scarce.\n",
        "\n",
        "- **Role in Morphology**: Unsupervised learning is often applied in morphological segmentation and clustering to identify patterns in word formation. By analyzing large corpora, unsupervised models can learn morphological patterns, deducing common morphemes and inflectional forms.\n",
        "\n",
        "- **Examples**:\n",
        "  - **Morphological Segmentation with Morfessor**: Morfessor is a popular unsupervised algorithm for morphological segmentation. It uses probabilistic models to split words into morphemes based on their statistical co-occurrence patterns, without needing labeled data. For example, it can analyze a corpus and deduce that \"-ing\" is a common suffix in English verbs.\n",
        "  - **Latent Dirichlet Allocation (LDA)**: Though originally used for topic modeling, LDA can be adapted to morphological induction by treating morphemes or sub-word units as “topics” in word formation. This approach can help discover recurring morphemes across words, clustering similar morphological forms together.\n",
        "\n",
        "### Combining Supervised and Unsupervised Methods\n",
        "\n",
        "Many recent approaches to morphological induction combine both supervised and unsupervised techniques to leverage the strengths of each. For instance, semi-supervised models may use a small amount of labeled data to guide the learning process while using unsupervised methods to expand learning on larger, unlabeled corpora. This approach helps balance the model’s ability to generalize across diverse morphological patterns with the precision of supervised methods.\n",
        "\n",
        "### Summary\n",
        "\n",
        "Supervised and unsupervised learning methods each have unique roles in morphological induction. Supervised learning models, such as CRFs and sequence-to-sequence networks, excel in tasks with ample labeled data, enabling precise morphological tagging and transformation. Unsupervised approaches, like Morfessor and LDA, are valuable for languages with limited resources, as they can autonomously discover morphological patterns. By combining both approaches, computational morphology can achieve robust and accurate morphological analysis across a wide range of languages and linguistic structures."
      ],
      "metadata": {
        "id": "TAJKbVfxiX65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Morphological analysis for Finnish\n",
        "We can start by analyzing Finnish words to identify their stems and affixes, utilizing basic morphological rules.\n",
        "\n",
        "The follwing code toy-example analyzes Finnish words to extract their stems and identify affixes (prefixes and suffixes)."
      ],
      "metadata": {
        "id": "POkpvHg1pOnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of Finnish words\n",
        "finnish_words = ['kirja', 'kirjat', 'kirjani', 'koti', 'kotini', 'koteja']\n",
        "\n",
        "# Function for morphological analysis\n",
        "def analyze_finnish_words(word_list):\n",
        "    analysis_results = []\n",
        "\n",
        "    for word in word_list:\n",
        "        stem = word\n",
        "        prefixes = []\n",
        "        suffixes = []\n",
        "\n",
        "        # Simple morphological rules for Finnish\n",
        "        # Remove known suffixes\n",
        "        if word.endswith('t'):\n",
        "            stem = word[:-1]  # Remove plural 't'\n",
        "            suffixes.append('t (plural)')\n",
        "        if word.endswith('ni'):\n",
        "            stem = word[:-2]  # Remove possessive 'ni'\n",
        "            suffixes.append('ni (my)')\n",
        "        if word.endswith('ja'):\n",
        "            stem = word[:-2]  # Remove plural form 'ja'\n",
        "            suffixes.append('ja (plural)')\n",
        "        if word.endswith('a'):\n",
        "            stem = word[:-1]  # General case for singular forms\n",
        "        # Additional rules can be added as needed\n",
        "\n",
        "        # Add the analysis to the results\n",
        "        analysis_results.append({\n",
        "            'original_word': word,\n",
        "            'stem': stem,\n",
        "            'prefixes': prefixes,\n",
        "            'suffixes': suffixes\n",
        "        })\n",
        "\n",
        "    return analysis_results\n",
        "\n",
        "# Run the morphological analysis\n",
        "results = analyze_finnish_words(finnish_words)\n",
        "\n",
        "# Display the results\n",
        "for result in results:\n",
        "    print(f\"Original Word: {result['original_word']}\")\n",
        "    print(f\"Stem: {result['stem']}\")\n",
        "    print(f\"Prefixes: {result['prefixes']}\")\n",
        "    print(f\"Suffixes: {result['suffixes']}\")\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "id": "Dd7QUyKipW_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285ac808-44f2-4eb8-91c1-91c4720819c1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Word: kirja\n",
            "Stem: kirj\n",
            "Prefixes: []\n",
            "Suffixes: ['ja (plural)']\n",
            "---\n",
            "Original Word: kirjat\n",
            "Stem: kirja\n",
            "Prefixes: []\n",
            "Suffixes: ['t (plural)']\n",
            "---\n",
            "Original Word: kirjani\n",
            "Stem: kirja\n",
            "Prefixes: []\n",
            "Suffixes: ['ni (my)']\n",
            "---\n",
            "Original Word: koti\n",
            "Stem: koti\n",
            "Prefixes: []\n",
            "Suffixes: []\n",
            "---\n",
            "Original Word: kotini\n",
            "Stem: koti\n",
            "Prefixes: []\n",
            "Suffixes: ['ni (my)']\n",
            "---\n",
            "Original Word: koteja\n",
            "Stem: kotej\n",
            "Prefixes: []\n",
            "Suffixes: ['ja (plural)']\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To perform morphological analysis in Finnish using a pre-coded morphological analyzer, we can use libraries like **nltk**. Bun let's use **SpaCy** for a change.\n",
        "\n",
        "\n",
        "SpaCy is an open-source natural language processing (NLP) library in Python designed specifically for advanced NLP tasks. It provides tools for text processing, including tokenization, part-of-speech tagging, dependency parsing, named entity recognition, and more. If you are interested, read more in [their website](https://spacy.io/)\n",
        "\n",
        "Let's start by downloading spacy and a library for Finnish (see documentation [here](https://spacy.io/models/fi#fi_core_news_sm))"
      ],
      "metadata": {
        "id": "KNloud-Fp0KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download fi_core_news_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6FP4YihqBlV",
        "outputId": "b4a1a2b2-3928-4ba9-92fc-f5cdb6224a04"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting fi-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fi_core_news_sm-3.7.0/fi_core_news_sm-3.7.0-py3-none-any.whl (14.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from fi-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: fi-core-news-sm\n",
            "Successfully installed fi-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fi_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can use it to get an analysis like the one we did before, but more *profesh*."
      ],
      "metadata": {
        "id": "VMlAEZsRrDUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the Finnish language model\n",
        "nlp = spacy.load('fi_core_news_sm')\n",
        "\n",
        "# Define a list of Finnish words\n",
        "finnish_words = ['kirja', 'kirjat', 'kirjani', 'koti', 'kotini', 'koteja']\n",
        "\n",
        "# Function for morphological analysis using SpaCy\n",
        "def analyze_finnish_words(word_list):\n",
        "    analysis_results = []\n",
        "\n",
        "    for word in word_list:\n",
        "        doc = nlp(word)\n",
        "\n",
        "        for token in doc:\n",
        "            analysis_results.append({\n",
        "                'original_word': token.text,\n",
        "                'lemma': token.lemma_,\n",
        "                'part_of_speech': token.pos_,\n",
        "                'morphological_features': token.morph,\n",
        "            })\n",
        "\n",
        "    return analysis_results\n",
        "\n",
        "# Run the morphological analysis\n",
        "results = analyze_finnish_words(finnish_words)\n",
        "\n",
        "# Display the results\n",
        "for result in results:\n",
        "    print(f\"Original Word: {result['original_word']}\")\n",
        "    print(f\"Lemma: {result['lemma']}\")\n",
        "    print(f\"Part of Speech: {result['part_of_speech']}\")\n",
        "    print(f\"Morphological Features: {result['morphological_features']}\")\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9Zz0O6VqDNv",
        "outputId": "6ce8d447-64dc-4180-d408-7f489fd59fdf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Word: kirja\n",
            "Lemma: kirja\n",
            "Part of Speech: NOUN\n",
            "Morphological Features: Case=Nom|Number=Sing\n",
            "---\n",
            "Original Word: kirjat\n",
            "Lemma: kirja\n",
            "Part of Speech: NOUN\n",
            "Morphological Features: Case=Nom|Derivation=Ja|Number=Plur\n",
            "---\n",
            "Original Word: kirjani\n",
            "Lemma: kirjani\n",
            "Part of Speech: VERB\n",
            "Morphological Features: Case=Gen|Degree=Pos|Number=Sing|Number[psor]=Sing|PartForm=Pres|Person[psor]=1|VerbForm=Part|Voice=Act\n",
            "---\n",
            "Original Word: koti\n",
            "Lemma: koti\n",
            "Part of Speech: NOUN\n",
            "Morphological Features: Case=Nom|Number=Sing\n",
            "---\n",
            "Original Word: kotini\n",
            "Lemma: koti\n",
            "Part of Speech: NOUN\n",
            "Morphological Features: Case=Gen|Number=Sing|Number[psor]=Sing|Person[psor]=1\n",
            "---\n",
            "Original Word: koteja\n",
            "Lemma: koti\n",
            "Part of Speech: NOUN\n",
            "Morphological Features: Case=Par|Number=Plur\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4\n",
        "**Q1.** Analyze More Complex Words by extending the list of Finnish words to include more complex words with various affixes and analyze their morphological structures.\n"
      ],
      "metadata": {
        "id": "yMLW5IVrstUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To analyze the morphological structures of more complex Finnish words, we’ll start by extending the list to include words with multiple affixes that illustrate various morphological processes in Finnish. Finnish is an agglutinative language, meaning it often builds words by attaching a series of affixes (such as case markers, possessive suffixes, and plural forms) to base forms. Here is an analysis of some complex Finnish words with their morphological structures broken down.\n",
        "\n",
        "### Extended List of Finnish Words and Morphological Analysis\n",
        "\n",
        "1. **kirjoittaminen** (\"writing\")\n",
        "   - **kirjoit-**: root meaning \"to write\"\n",
        "   - **-ta-**: infinitive suffix\n",
        "   - **-minen**: noun-forming suffix, turning the verb into a noun that describes the action (e.g., \"writing\" as a noun)\n",
        "   - **Structure**: root + infinitive + noun-forming suffix\n",
        "\n",
        "2. **kirjoittamattomuus** (\"lack of writing\" or \"non-writing\")\n",
        "   - **kirjoit-**: root meaning \"to write\"\n",
        "   - **-ta-**: infinitive suffix\n",
        "   - **-matto-**: negation suffix, indicating \"not\"\n",
        "   - **-muus**: noun-forming suffix that adds the sense of a state or quality\n",
        "   - **Structure**: root + infinitive + negation + noun-forming suffix\n",
        "\n",
        "3. **rakennustyömaa** (\"construction site\")\n",
        "   - **raken-**: root meaning \"to build\"\n",
        "   - **-nus**: nominalizing suffix indicating \"construction\" or \"building\"\n",
        "   - **työ**: noun meaning \"work\"\n",
        "   - **maa**: noun meaning \"ground\" or \"site\"\n",
        "   - **Structure**: root + nominalizer + compound noun\n",
        "\n",
        "4. **opiskelijayhdistys** (\"student association\")\n",
        "   - **opiskeli-**: root meaning \"to study\"\n",
        "   - **-ja**: agent suffix, turning the verb root into \"student\" (one who studies)\n",
        "   - **yhdistys**: noun meaning \"association\"\n",
        "   - **Structure**: root + agent suffix + compound noun\n",
        "\n",
        "5. **mielipiteettömyys** (\"lack of opinion\" or \"opinionlessness\")\n",
        "   - **mieli**: noun meaning \"mind\" or \"opinion\"\n",
        "   - **-pide-**: derived form meaning \"opinion\" or \"view\"\n",
        "   - **-ttö-**: negation suffix, indicating absence or lack\n",
        "   - **-myys**: noun-forming suffix that conveys a state or quality\n",
        "   - **Structure**: noun + derived form + negation + noun-forming suffix\n",
        "\n",
        "6. **ympäristöystävällisyys** (\"environmental friendliness\")\n",
        "   - **ympäristö**: noun meaning \"environment\"\n",
        "   - **ystävä**: noun meaning \"friend\"\n",
        "   - **-llinen**: adjective-forming suffix, creating \"friendly\" (environment-friendly)\n",
        "   - **-yys**: noun-forming suffix indicating a quality or state\n",
        "   - **Structure**: noun + compound noun + adjective suffix + noun-forming suffix\n",
        "\n",
        "7. **yksinkertaisuudessaan** (\"in its simplicity\")\n",
        "   - **yksi-**: root meaning \"one\" or \"single\"\n",
        "   - **-nkertainen**: adjective meaning \"simple\" or \"onefold\"\n",
        "   - **-suus**: noun-forming suffix for state or quality, creating \"simplicity\"\n",
        "   - **-ssa**: inessive case marker, meaning \"in\"\n",
        "   - **-an**: possessive suffix, indicating \"its\"\n",
        "   - **Structure**: root + adjective + noun-forming suffix + case marker + possessive suffix\n",
        "\n",
        "8. **tietokonepelisuunnittelu** (\"computer game design\")\n",
        "   - **tieto-**: noun meaning \"information\"\n",
        "   - **kone**: noun meaning \"machine\" (together, \"computer\")\n",
        "   - **peli**: noun meaning \"game\"\n",
        "   - **suunnittelu**: noun meaning \"design\" or \"planning\"\n",
        "   - **Structure**: compound noun + noun + noun\n",
        "\n",
        "### Summary\n",
        "\n",
        "These Finnish words demonstrate the use of multiple affixes, compound structures, and derivational and inflectional morphemes. By analyzing the words into their roots and affixes, we gain insight into how Finnish morphology builds complex meanings. Each word includes a combination of base forms and affixes that together convey nuanced concepts typical of an agglutinative language like Finnish."
      ],
      "metadata": {
        "id": "rPjIMUQKiytI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.** Visualize the results. Creating visualizations of the morphological features extracted can provide a better understanding of the results. (no need to answer anything, just learn how to do plots, you'll need it in the following part)"
      ],
      "metadata": {
        "id": "tLX-S8IRs6Cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib pandas\n",
        "\n",
        "# we will use pandas and matplotlib to create dataframes and plots\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load the results into a pandas dataframe\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "#initialize a figure\n",
        "plt.figure(figsize=(10, 6))\n",
        "df['part_of_speech'].value_counts().plot(kind='bar', color='skyblue')\n",
        "plt.title('Distribution of Parts of Speech in Finnish Words')\n",
        "plt.xlabel('Part of Speech')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "Ww8ymL1OrZat",
        "outputId": "74324209-46fa-4cc9-baac-de352d2f8b69"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# maybe it is more effective to show it as a pie\n",
        "df['part_of_speech'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
        "plt.title('Proportion of Parts of Speech')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "_HLwF5R-tXTH",
        "outputId": "d3cc2817-4b42-4760-f1b2-b21003805a37"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCHklEQVR4nO3dd3xT5eIG8CejbboXHbRAWygte4uIWAoICAiKP5aTqThRvOpV8cpQVEDFgeBiiaIgKFxFpowrAiKjIBu6GR2U7p3k/f2BPRJaSvebkzzfz6cf6MnJyZMQ8uSs92iEEAJEREQAtLIDEBGR9WApEBGRgqVAREQKlgIRESlYCkREpGApEBGRgqVAREQKlgIRESlYCkREpGApUKVCQ0Mxbtw42TEqdfbsWQwYMACenp7QaDRYt26d7EhSpaamYsSIEfD19YVGo8EHH3wgO1K9mzFjBjQaDS5fviw7iuqxFKph2bJl0Gg0yo/BYEBERASefvpppKamyo5XY3v27MGMGTOQlZUlO0qNjB07Fn/99Rdmz56NFStWoFu3bhXOl5CQYPHvp9Pp0KxZMwwfPhwxMTF1mmnhwoVYtmxZnS6zqqZOnYrNmzfjlVdewYoVK3DXXXfdcN68vDxMnz4d7dq1g6urK3x9fdGpUyc8++yzuHjxYgOmJmuhlx1AjWbNmoWwsDAUFRVh9+7dWLRoEX755RccO3YMLi4usuNV2549ezBz5kyMGzcOXl5eFredPn0aWq31fncoLCzE3r17MW3aNDz99NNVus/999+PwYMHw2Qy4eTJk1i0aBE2btyIffv2oVOnTnWSa+HChWjUqJGUtazt27fjnnvuwQsvvFDpfKWlpYiKisKpU6cwduxYPPPMM8jLy8Px48excuVKDB8+HEFBQQ2UmqwFS6EGBg0apHwbnTRpEnx9ffH+++9j/fr1uP/++yu8T35+PlxdXRsy5k1VJZOTk1MDpamZ9PR0AChXZpXp0qULHnroIeX322+/HcOGDcOiRYvw2Wef1SpPQUGB9C8GaWlpVXo91q1bh8OHD+Obb77BAw88YHFbUVERSkpK6ikhWTPr/QqoIn379gUAxMfHAwDGjRsHNzc3xMbGYvDgwXB3d8eDDz4I4OoH8b/+9S80bdoUTk5OiIyMxLvvvovrB6vVaDR4+umn8c033yAyMhIGgwFdu3bF//73v3KPf/jwYQwaNAgeHh5wc3NDv379sG/fPot5yjZ97dq1C08++ST8/f3RpEkTzJgxAy+++CIAICwsTNm0kpCQAKDifQpxcXEYOXIkfHx84OLigh49emDDhg0W8+zcuRMajQarV6/G7Nmz0aRJExgMBvTr1w/nzp2r0ut6s+c1Y8YMhISEAABefPFFaDQahIaGVmnZ17r+32/9+vUYMmQIgoKC4OTkhBYtWuCNN96AyWSyuF90dDTatWuHgwcPIioqCi4uLnj11VcRGhqK48ePY9euXcrrGR0dDeDqt/OZM2eiZcuWMBgM8PX1Ra9evbB169ab5rzZ6172byyEwCeffKI89o3ExsYCuFqK1zMYDPDw8FB+L3tPx8XFYeDAgXB1dUVQUBBmzZpV7r1rNpvxwQcfoG3btjAYDAgICMDkyZORmZlZ7nE2btyIO+64A66urnB3d8eQIUNw/PjxcvOdOnUKo0aNgp+fH5ydnREZGYlp06aVmy8rK0tZ4/X09MT48eNRUFBww9eAyuOaQh0o+8/l6+urTDMajRg4cCB69eqFd999Fy4uLhBCYNiwYdixYwcmTpyITp06YfPmzXjxxRdx4cIFzJ8/32K5u3btwqpVqzBlyhQ4OTlh4cKFuOuuu7B//360a9cOAHD8+HHccccd8PDwwEsvvQQHBwd89tlniI6Oxq5du3DrrbdaLPPJJ5+En58fXn/9deTn52PQoEE4c+YMvv32W8yfPx+NGjUCAPj5+VX4XFNTU9GzZ08UFBRgypQp8PX1xfLlyzFs2DCsWbMGw4cPt5j/nXfegVarxQsvvIDs7GzMnTsXDz74IP74449KX9OqPK/77rsPXl5emDp1qrJJyM3NrQr/Ypau//dbtmwZ3Nzc8Pzzz8PNzQ3bt2/H66+/jpycHMybN8/ivhkZGRg0aBDGjBmDhx56CAEBAYiOjsYzzzwDNzc35YMrICAAwNUie/vttzFp0iR0794dOTk5OHDgAA4dOoT+/fvfMGNVXveoqCisWLECDz/8MPr3749HHnmk0uddVqhfffUVXnvttUoLBABMJhPuuusu9OjRA3PnzsWmTZswffp0GI1GzJo1S5lv8uTJWLZsGcaPH48pU6YgPj4eCxYswOHDh/H777/DwcEBALBixQqMHTsWAwcOxJw5c1BQUIBFixahV69eOHz4sFLwR48exR133AEHBwc89thjCA0NRWxsLH766SfMnj3bIuOoUaMQFhaGt99+G4cOHcKXX34Jf39/zJkzp9LnRtcQVGVLly4VAMS2bdtEenq6SE5OFt99953w9fUVzs7O4vz580IIIcaOHSsAiJdfftni/uvWrRMAxJtvvmkxfcSIEUKj0Yhz584p0wAIAOLAgQPKtMTERGEwGMTw4cOVaffee69wdHQUsbGxyrSLFy8Kd3d3ERUVVS57r169hNFotHj8efPmCQAiPj6+3HMOCQkRY8eOVX5/7rnnBADx22+/KdNyc3NFWFiYCA0NFSaTSQghxI4dOwQA0bp1a1FcXKzM++GHHwoA4q+//ir/Al+jqs8rPj5eABDz5s2rdHnXzjtz5kyRnp4uUlJSxM6dO0Xnzp0FALF27VohhBAFBQXl7jt58mTh4uIiioqKlGm9e/cWAMSnn35abv62bduK3r17l5vesWNHMWTIkJtmvV5VX3chrr53nnrqqZsus6CgQERGRgoAIiQkRIwbN04sXrxYpKamlpu37D39zDPPKNPMZrMYMmSIcHR0FOnp6UIIIX777TcBQHzzzTcW99+0aZPF9NzcXOHl5SUeffRRi/lSUlKEp6enxfSoqCjh7u4uEhMTLeY1m83K36dPny4AiAkTJljMM3z4cOHr63vT14L+wVKohrIP1ut/QkJCxKZNm5T5yv4DXf8mfuyxx4ROpxM5OTkW0/fu3SsAiI8//liZBkDcdttt5TKMHj1auLi4CKPRKIxGo3BxcRGjRo0qN9/kyZOFVqsV2dnZFtmXL19ebt7qlEJERITo3r17ufnefvttiw/7slKYO3euxXyHDh0SAMT69evLLaNMdZ5XTUrh+h8PDw8xZ86cCu+Tk5Mj0tPTxddffy0AiJiYGOW23r17CycnJ4vSK3OjUujdu7cIDQ0VZ86cuWnea1X1dRei6qUghBBZWVnixRdfFCEhIcrrodVqxdNPP21RgGXv6dOnT1vcf+PGjQKA+Pbbb4UQQkyZMkV4enqKtLQ0kZ6ebvHj5uYmJk2aJIQQ4ocffhAAxPbt28vNN2DAABEeHi6EECItLU0AEM8++2ylz6OsFPbv328x/f333xcAlPcL3Rw3H9XAJ598goiICOj1egQEBCAyMrLcETp6vR5NmjSxmJaYmIigoCC4u7tbTG/durVy+7VatmxZ7rEjIiJQUFCg7GAtKChAZGRkuflat24Ns9mM5ORktG3bVpkeFhZWjWdaXmJiYrlNUtc/h7JNWwDQrFkzi/m8vb0BoMLty2XS09Or/byq47HHHsPIkSOh1Wrh5eWFtm3bWuxQP378OF577TVs374dOTk5FvfNzs62+D04OBiOjo5VfuxZs2bhnnvuQUREBNq1a4e77roLDz/8MDp06FDp/ar7uleVp6cn5s6di7lz5yIxMRG//vor3n33XSxYsACenp548803lXm1Wi2aN29ucf+IiAgAUPZBnT17FtnZ2fD396/w8dLS0pT5gH/251yvbH9GXFwcAFT5uVX2frt2HwndGEuhBrp3737DY+HLODk5WeWhnM7Ozg36eDqdrsLpQuJVYFu2bIk777yzwtuysrLQu3dveHh4YNasWWjRogUMBgMOHTqEf//73zCbzRbzV/f1jIqKQmxsLNavX48tW7bgyy+/xPz58/Hpp59i0qRJNX5OdSEkJAQTJkzA8OHD0bx5c3zzzTcWpVAVZrMZ/v7++Oabbyq8vWxfVdnruGLFCgQGBpabT6+v2UeTNb7f1Ial0IBCQkKwbds25ObmWqwtnDp1Srn9WmXfpq515swZuLi4KP+5XFxccPr06XLznTp1ClqtFk2bNr1prpvtYLz+Odzo8cpury0/P786eV41sXPnTmRkZOCHH35AVFSUMr3syKSqquw19fHxwfjx4zF+/Hjk5eUhKioKM2bMqLQUGuJ1L+Pt7Y0WLVrg2LFjFtPNZjPi4uKUtQPg6vsRgLJTuEWLFti2bRtuv/32SguzRYsWAAB/f/8bFjQAZc3k+ixUf6zvq6wNKzthasGCBRbT58+fD41Gg0GDBllM37t3Lw4dOqT8npycjPXr12PAgAHQ6XTQ6XQYMGAA1q9fr6y+A1ePVFm5ciV69epVpVXmsnMVqnJG8+DBg7F//37s3btXmZafn4/PP/8coaGhaNOmzU2XcTN19bxq+tiA5TfLkpISLFy4sFrLcXV1rfD1zMjIsPjdzc0N4eHhKC4urnR59fG6HzlypMJhIRITE3HixIkKN99d+94VQmDBggVwcHBAv379AFw9+sdkMuGNN94od1+j0ai8JgMHDoSHhwfeeustlJaWlpu3bPOon58foqKisGTJEiQlJVnMw2//9YNrCg1o6NCh6NOnD6ZNm4aEhAR07NgRW7Zswfr16/Hcc88p357KtGvXDgMHDrQ4JBUAZs6cqczz5ptvYuvWrejVqxeefPJJ6PV6fPbZZyguLsbcuXOrlKtr164AgGnTpmHMmDFwcHDA0KFDKzyx7eWXX8a3336LQYMGYcqUKfDx8cHy5csRHx+PtWvX1tkms7p4XjXRs2dPeHt7Y+zYsZgyZQo0Gg1WrFhR7Q+grl27YtGiRXjzzTcRHh4Of39/9O3bF23atEF0dDS6du0KHx8fHDhwAGvWrLnp2dj18bpv3boV06dPx7Bhw9CjRw/lPIQlS5aguLgYM2bMsJjfYDBg06ZNGDt2LG699VZs3LgRGzZswKuvvqqsufbu3RuTJ0/G22+/jZiYGAwYMAAODg44e/Ysvv/+e3z44YcYMWIEPDw8sGjRIjz88MPo0qULxowZAz8/PyQlJWHDhg24/fbblQL66KOP0KtXL3Tp0gWPPfYYwsLCkJCQgA0bNtT58CQEHpJaHWVH8Pz555+Vzjd27Fjh6upa4W25ubli6tSpIigoSDg4OIiWLVuKefPmWRxeJ8Q/R5B8/fXXomXLlsLJyUl07txZ7Nixo9wyDx06JAYOHCjc3NyEi4uL6NOnj9izZ0+1sr/xxhsiODhYaLVaiyORrj/6SAghYmNjxYgRI4SXl5cwGAyie/fu4ueff7aYp+zoo++//95ietkRQEuXLq0wR3WfV02OPrrZvL///rvo0aOHcHZ2FkFBQeKll14SmzdvFgAsXv/evXuLtm3bVriMlJQUMWTIEOHu7i4AKEcivfnmm6J79+7Cy8tLODs7i1atWonZs2eLkpKSm+avyusuRNWPPoqLixOvv/666NGjh/D39xd6vV74+fmJIUOGiO3bt1vMW/aejo2NFQMGDBAuLi4iICBATJ8+3eJw2DKff/656Nq1q3B2dhbu7u6iffv24qWXXhIXL160mG/Hjh1i4MCBwtPTUxgMBtGiRQsxbtw4i0OxhRDi2LFjYvjw4cpzj4yMFP/5z3+U28uOPio7NLZM2fu+oiPrqGIaIbgOZo00Gg2eeuqpcpuaiGQYN24c1qxZg7y8PNlRqJ5xnwIRESlYCkREpGApEBGRgvsUiIhIwTUFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIoVedgCiulZUakJGfgky80uQkV+C7MJS5BcbkV9sRG7R1T/zS4woNpqh02ig12mg12qh02qg12qg0139U6/VWvzu7KiHn5sT/D2c4O/uBH93Axz1/F5FtoWlQKpTYjQjMSMfcZfzEX85H/HpV/+8kFWIK/klKCw1NUgOjQbwcnaAv7sB/h5O8HN3QoCHQSmMYG9nRAS4wcWR/81IPTRCCCE7BFFFkq8UIO5yPhL+/vC/WgJ5uJBZCLNK3rVaDRDi64pWge5o3dhD+bOpj4vsaEQVYimQVSgxmvHXhSwcSMjEnwmZOJSUiSv5JbJj1Rt3g/6aovBA68ZX/25w0MmORnaOpUBSZBeW4mDiFRxIyMSBhEwcOZ+FYqNZdiypHHVadGrqhR4tfHFbc190CfGCk54lQQ2LpUANIrugFDvPpGF//NUiOJOWC77zKuek16JzMy/c0dIPvSP80DbIAxqNRnYssnEsBao3ablF2HI8FZuOpWBfXAaMatkRYKUauTkhKqIRekf4IaqlH7xdHWVHIhvEUqA6lXylAJuPp2DTsRQcSspUzQ5htdFqgB7NfXFv52AMahcId4OD7EhkI1gKVGvn0vKw6dglbDqegmMXcmTHsTtOei3ubB2AezsHIzrSDw46njtBNcdSoBpJyS7C6gPJWB9zAbHp+bLj0N+8XRwwuH1jDO8cjK4h3twHQdXGUqAqM5sFdpxOw7f7k7DjdDpM3DZk1Zr6OOOejsG4t3Mwwv3dZMchlWAp0E2l5RRh5f4krP4zGRezi2THoRro0swLj97RHAPbBkKr5doD3RhLgW7ocFImlv6egI3HLqHUxLeJLQjxdcHEXmEY2bUpnB15DgSVx1IgC6UmMzYcvYSlexJwJDlLdhyqJ94uDnjw1hCM7RkKP3cn2XHIirAUCABgNJmx+sB5LNh+lpuI7IijXovhnYLxaFQYwv3dZcchK8BSsHMms8CPhy/go1/PIulKgew4JIlGA/SJ9MejdzTHbS18ZcchiVgKdkoIgZ+OXsIH284gjoeU0jW6hXjj1SGt0aWZt+woJAFLwQ5tOpaCD7adwamUXNlRyIoN6dAYL9/VisN82xmWgh3ZcSoN7289g78uZMuOQirhqNPikdtC8EzflvB04VAa9oClYAcOJWVi9oaTOJiYKTsKqZSXiwOe6dsSj9wWwmE0bBxLwYZlF5ZizqZT+HZ/EoeppjoR6uuCl+5qhcHtG8uOQvWEpWCj1sdcwBs/n8TlvGLZUcgGdQ3xxjTujLZJLAUbk5iRj9fWHcNvZy/LjkI2TqMBxtzSDK8ObsWhu20IS8FGlBjN+GxXLBbsOGf3l7WkhhXoYcDs4e3Qr3WA7ChUB1gKNuCPuAy8+uNfHMKapBraMQgzhraBrxuHzVAzloKKZeaX4K1fTmLNofPckUxWwcfVEW/c0w5DOnBHtFqxFFRqX1wGnv3uMFJzuCOZrM89nYIw65528HTmvga1YSmojNks8NH2s/h4+zle5IasWqCHAfNGdsAdLf1kR6FqYCmoSFpOEZ79LgZ74zJkRyGqEo0GeLhHCF4d3BoGB16/QQ1YCiqx60w6nl8Vg4z8EtlRiKqtfbAnPn24K4K9nGVHoZtgKVg5o8mMd7ecwWf/i+XOZFI1H1dHLLi/M3qGN5IdhSrBUrBiF7IK8czKQziUlCU7ClGd0Gk1+PddkXgsqoXsKHQDLAUrteV4Cl5ccxTZhaWyoxDVubs7NMa8ER15nWgrxFKwMkIIvLflDBbsOCc7ClG9ahXojs8e7ooQX1fZUegaLAUrUlRqwgvfH8HPRy/JjkLUIDydHfDBmE7oE+kvOwr9jaVgJS7nFePRrw7gMPcfkJ3RaoCpd0bg6b7h0Gg0suPYPZaCFTibmosJy/9E8pVC2VGIpBnSoTHmj+oERz0v4iMTS0GyP+Iy8OhXB5BTZJQdhUi63hF++PShrtwBLRFLQaJNxy7h2e9iONQ10TVuCfXG4nG3wIPXaJCCpSDJ1/sS8fr6Y+DwRUTltQ3ywFcTunMYbglYChK8v+U0PtrOQ06JKtPczxVfT7wVQRwao0GxFBrYGz+fwOLd8bJjEKlCsJczvp50K8Ia8VyGhsLd/A1ozqZTLASiariQVYiRn+7FiYs5sqPYDZZCA/lg2xks2hkrOwaR6lzOK8aYz/fiYGKm7Ch2gaXQABbtjMUH287KjkGkWjlFRjy8+A/s47VE6h1LoZ4t2R2POZtOyY5BpHoFJSY8uvwAjl/Mlh3FprEU6tE3fyRi1s8nZMcgshm5xUaMW/onkq8UyI5is1gK9eT7A8l4bd0x2TGIbE56bjEeXvwHLucVy45ik1gK9WB9zAX8e+1RXimNqJ4kZBRg3NL9yCvm8DB1jaVQxzYdS8G/Vh/hmcpE9ezYhRw8vuIgSjhMTJ1iKdSho+ez8NyqwzCyEYgaxO5zl/H86hjwHNy6w1KoI2m5RXjsq4MoKuW3FqKG9PPRS5j5Ew/oqCsshTpQbDRh8oqDSMkpkh2FyC4t25OAT3gJ2zrBUqgDr/zwF6+YRiTZvM2nsfbgedkxVI+lUEtf/C8OPxy6IDsGEQF49ce/8Nd5ntxWGyyFWth5Og3v8GxlIqtRbDTj8a8P4kp+iewoqsVSqKHY9Dw88+1hmHikEZFVuZBViCn8v1ljLIUayC4sxaPLDyCX11Umskq7z13G3M1ci68JlkI1mcwCT688hLjL+bKjEFElPtsVh83HU2THUB2WQjV99OtZ/Hb2suwYRFQFL605ivOZHDyvOlgK1RCTnMVjoYlUJLuwFE+vPIxSE08qrSqWQhUVlpjw/KoYDmFBpDIxyVmYy6MEq6zGpTBu3DhoNBq88847FtPXrVsHjUaj/G4ymTB//ny0b98eBoMB3t7eGDRoEH7//XeL+82YMQOdOnUq9zgJCQnQaDSIiYkBAOzcuRMajQZt27aFyWSymNfLywvLli2r6VOq1Fu/nOR+BCKV+nJ3PH49mSo7hirUak3BYDBgzpw5yMys+NqpQgiMGTMGs2bNwrPPPouTJ09i586daNq0KaKjo7Fu3boaP3ZcXBy++uqrGt+/OnadSceKfYkN8lhEVPeEuLp/IZPnL9xUrUrhzjvvRGBgIN5+++0Kb1+9ejXWrFmDr776CpMmTUJYWBg6duyIzz//HMOGDcOkSZOQn1+zb9/PPPMMpk+fjuLi+r3QRlZBCV5ac6ReH4OI6l9GfgmvhFgFtSoFnU6Ht956Cx9//DHOny8/5sjKlSsRERGBoUOHlrvtX//6FzIyMrB169YaPfZzzz0Ho9GIjz/+uEb3r6pp644hNYdXeCKyBT8evoCdp9Nkx7Bqtd7RPHz4cHTq1AnTp08vd9uZM2fQunXrCu9XNv3MmTM1elwXFxdMnz4db7/9NrKz62esk/UxF7Dh6KV6WTYRyTHtx2PI5xXbbqhOjj6aM2cOli9fjpMnT5a7rT4vfjFx4kT4+vpizpw5db7sS9mF+A+vsUxkcy5kFWLe5tOyY1itOimFqKgoDBw4EK+88orF9IiIiAqLAoAyPSIiAgDg4eFR4Tf+rKwsAICnp2e52/R6PWbPno0PP/wQFy9erM1TsCCEwIvfH0UOh7Egsklf7U3AwcSKD5Cxd3V2nsI777yDn376CXv37lWmjRkzBmfPnsVPP/1Ubv733nsPvr6+6N+/PwAgMjIS58+fR2qq5WFjhw4dgsFgQLNmzSp83JEjR6Jt27aYOXNmXT0VrD6QjN3neNYyka0yC+DltUd5fecK1FkptG/fHg8++CA++ugjZdqYMWMwfPhwjB07FosXL0ZCQgKOHj2KyZMn47///S++/PJLuLq6AgAGDhyIyMhI3H///dizZw/i4uKwZs0avPbaa3j22Weh0+lu+NjvvPMOlixZUuMjma6VXVCKOZu4aklk686m5WEBRygop07PaJ41axbM5n+aV6PRYPXq1Xj11Vcxf/58REZG4o477kBiYiJ27tyJe++9V5lXr9djy5YtaNasGe6//360a9cO06dPx7PPPos33nij0sft27cv+vbtC6Ox9pt73tt6mmOxE9mJRTvP4XRKruwYVkUj6nNPsMocv5iNYQt+5zjsRHakU1Mv/PBET2i1mpvPbAc49tHfhBCYvv44C4HIzsQkZ2Hl/iTZMawGS+Fv62Mu4gCPRiCySx/9ehaFJaabz2gHWAoAikpNHEWRyI6l5RZjye/xsmNYBZYCgMW743Exu0h2DCKS6NNdscgq4EEmdl8K6bnFWLQzVnYMIpIst8jIi2iBpYD5284gj+OgEBGAr/Ym4mJWoewYUtl1KZxLy8WqP5NlxyAiK1FsNOODbTUbpNNW2HUpLNwRy0NQicjC2kMXcC7Nfk9os9tSSL5SgP8eqbtB9IjINpjMAnPteKgbuy2FL36Lg5FrCURUgS0nUu12FFW7LIXLecVYfYD7EojoxubY6blLdlkKS3bHo6iUQ+YS0Y3tj79il2sLdlcKuUWlWLEvUXYMIlKBpXZ4lrPdlcKKfYnI5RXViKgKNh1LwaVs+zpvwa5KoajUhCW7E2THICKVMJoFvtprX1sW7KoUvj+QjMt5xbJjEJGKfLs/CUWl9jOCqt2UgtFkxmf/i5Mdg4hUJqugFD8eviA7RoOxm1LY8NclnM+0r22DRFQ3lv2eIDtCg7GbUuAYR0RUU6dTc/H7ucuyYzQIuyiFC1mF2BuXITsGEamYvRyeahelsPbgeQiOaEFEtbD9VBoSM/Jlx6h3Nl8KQgisOXhedgwiUjmzAJbtSZAdo97ZfCnsj7+CpCsFsmMQkQ344dAFlBhte4gcmy8FriUQUV3JLizFztNpsmPUK5suhYISI37565LsGERkQ9bH2PZ1WGy6FH75KwX5JfZzJiIR1b9fT6Xa9HXd9bID1Kc1B9VxboIwm5C9eyXyTuyEOT8TOjcfuLbrB8+eY6DRaAAAWbu/Qf7J32DKTYdGq4djYDi8oh6BU1DkDZebe/gX5B7+BcbsVACAQ6Nm8Op5P5xbdFPmufLrF8g/9is0DgZ49R4Lt7Z9lNvyT+1G/rFf4T9iej09cyL1KSo1Y9OxFIzo2kR2lHphs6WQfKUAf8RfkR2jSnL+WIvcmI3wHTIVjo2aofjSWWRs/BBaJ1d4dBsGAHDwCYZP/8eh9wqEKC1G7oH1SF31HwRP/gI6F88Kl6tz94V377HQewcBAPKO/Yq0H95E43EfwtEvBAXn/kD+yV3wH/UGjJkXkbHxQziHdYHOxRPm4nxk/e8rBIx5s8FeByK1WB9zwWZLwWY3H609pJ5zE4ovnIRz+K1waXEL9J4BcG3VC86hnVFy6Ywyj2ubaDiHdoKDVyAc/ULg3XcSREkBStJufEKNS/itcG5xCxx8guHgEwzvqEegdTSg+OLV68+WZiTD0LQ9nBq3hGub3tA4uihrFZk7lsK982DoPfzr98kTqdDe2AxkFZTIjlEvbLYUNh9PlR2hypyCW6Mo8QhKr1wddKskLQ5F50/A0LxrhfMLUylyYzZB4+QKR/+wKj2GMJuQf2IXzKVFcApuBQBw9AtDSco5mIryUJxyDsJYDL13EIrOH0dJaizcuw6tmydIZGOMZoEtJ9TzGVMdNrn5KDWnCCcv5ciOUWUePUbAXFyAi188Dmi1gNkMr6iHLbbvA0DBuf24/N+5EKXF0Ll5I2D0GzfcdFSmJD0BKStegDCWQOPoDP/h0+DYqBkAwLl5V7i2jUbK8qnQ6B3RaMhUaB2ccGXzQvgOmXp1n8Shn6Fz9oDPwKfh6BdSb68Bkdps/OsSRnVrKjtGndMIoZaNLFW3+s9kvLT2qOwYVZZ/Yhcydy6Fd/R4OPiFoCQ1Dpm/fgHvvpPg1r6fMp+5pAim/CswF+Qg98hmFCUdReOH34PO1euGyxamUhhz0mEuLkDB6d3IO7IFAQ+8oxTD9bJ2r4S5OB9u7e9E6ur/IGjCJyg8tx+5h35G43Ef1vVTJ1ItR50WB/5zJzwMDrKj1Cmb3Hy0Q2Unl2TuXArPHiPg2qY3HP1C4dauL9xvuQfZ+763mE/raICDdxCcgluh0eBnodFqkXd0S6XL1ugcrt4nMBzevcfB0T8MuQf+W+G8pRnJyD+xA153PISipL9gaNIOOhdPuLS6AyWpsTAX88xwojIlJjO2n1TXZ01V2FwpGE1m7FbZELeitBjQWP5TaDRaQNzkdHohIEyl1XusG9xHCIGMzZ/Au+8kaB2dAWGGMP99LHbZnzfLQ2RntpxIkR2hztncPoWDiZnILVLXiSXO4d2RvWcVdB5+cGzUDCWpscj5cx3cOvQHcHWzUfbeVXAJvxU6Nx+YCnOQe+hnGHMz4BLZS1lO6nevwrnlbfD4ewdx5q5lcG7eDXoPP5hLCpF/YieKk/6C56hZ5TLkHdkMnbMHXMJvBXB153fW7pUovnAKhXEH4eDbDFqDWwO8GkTqsS/uCoQQyvlEtsDmSmHnmXTZEarN587JyPrta1zZshDmgmzo3Hzg1mkQvG4fAwDQaLUovXIe6et+hakwBzpnDzgGtkTgg3Msdv6WZqbAqfCfHeym/Gxc/vl9mPKvQOvkCke/UPiPmgXnsM4Wj2/Kz0T23tUIfGieMs0pKBIe3Ycjbc1MaF080WjI1Hp+FYjU50p+CU6n5qJVoIfsKHXG5nY0D/rwN1UdeURE6jZ9aBuMv71qh4argU3tU1DboahEpH77bOyqjjZVCrY+pC0RWZ/98Vf3K9gKGysF9e1PICJ1yywoxamUXNkx6ozNlILZLFR3KCoR2QZb2oRkM6UQm56nukNRicg2sBSs0OHkLNkRiMhO2dJ+BZsphSMsBSKSxJb2K9hMKcSwFIhIIlvZhGQTpVBUasJpG2lpIlKnQ0lZsiPUCZsoheMXc2A028b2PCJSp7OptvHF1CZK4QTPYiYiyeIu58NkA19ObaMULrIUiEiuEqMZiRn5smPUmk2UAsc7IiJrcDYtT3aEWlN9KZjNgjuZicgqnGMpyBefkY/CUpPsGERENrGzWfWlcDZV/c1MRLbhjA18Hqm+FC5kFcqOQEQEAIi7nAezyo9AUn0pXGIpEJGVKCo1IzmzQHaMWlF9KVzMZikQkfVQ+yZt9ZdCVpHsCEREijNp6t7ZbAOlwDUFIrIeyVfU/Zmk6lIoNZlxOa9YdgwiIsWVfHV/Jqm6FFKyi6DyHf1EZGOu5JfIjlArqi4FbjoiImuTwVKQ51I2dzITkXXhmoJEPByViKxNdmEpjCaz7Bg1pu5S4OYjIrIyQly9ZrNaqboU0nPVvZefiGyTmjchqboUCkvVu4pGRLYrQ8WHpaq6FIo4ZDYRWSGuKUhSbOSaAhFZH5aCJMVcUyAiK3Q5j6UgBdcUiMga5RUZZUeoMXWXAtcUiMgKmczq/cKq6lIo4poCEVkhk1DvoGyqLgWuKRCRNTKpeKROVZcC1xSIyBqxFCQwmsyqfuGJyHYZVfzZpJcdoKa4lkB1yV1vxG9NFsGpVN2XUiTrUOLWH0An2TFqRLWlYDKpt4nJ+uQa9fhT3w39Uz6WHYVsgHPTjrIj1JhqNx85O+pkRyAbMyW+O0q8msuOQbZAo9qPVvWWgqNeCwedRnYMsiGFJh0WOU6QHYNsAUtBDlcn1W79Iis1P6k5MhpHyY5BaqdV75YMdZeCI0uB6t6/skdDaPneolrQO8tOUGPqLgUn9bYxWa+dV7xxPHiU7BikZs5eshPUmMpLgd/mqH5MTu4Ps7Ov7BikVgYv2QlqTN2lwM1HVE8uFDnhJ59xsmOQWnFNQQ5uPqL69EJ8FxT5tJYdg9SIawpycE2B6lOpWYN5mnGyY5AacU1BDu5ToPq2+EJTpAT1lx2D1MbgKTtBjam6FFy4+YgawJQr/wehc5Idg9SEm4/k8DA4yI5AdmB/lgcOBT0gOwapCTcfyRHoYZAdgezE44nRMLkGyo5BaqB3BvTqXbNUdSkEe6v3rEFSl/QSB6zyGC87BqmBZ7DsBLWi7lLwYilQw5mW0A75fp1kxyBr5x0qO0GtqLoUAj0N0HKgVGogQmgwo/QRCPBNR5VgKcjjoNPCz1292+5Ifb5PCURyk7tlxyBrxlKQq4m3i+wIZGeeSB0G4eAqOwZZK5aCXCG+LAVqWMdzXbE78GHZMchaeYXITlArqi+FMF9+Y6OG92R8Txg9msmOQdaIawpyhfmxFKjh5Rr1WOLCS3fSdZx9AIOH7BS1ovpSCOWaAknyVkIEsgN6yI5B1kTlawmADZRCWCOWAsnzSsEDEBqOwUV/8w2XnaDWVF8Krk56DndB0vyS3ghnm9wnOwZZi8YdZSeoNdWXAgB0aKLeYWpJ/R6/MAjCie9BAhDUSXaCWrOJUujUzEt2BLJjcQUGbPEbJzsGSacBAjvIDlFrtlEKTb1kRyA791x8N5R4qX97MtWCbwvVH3kE2EgpdGzixTGQSKpCkw4fOfAQVbvWuJPsBHXCJkrB1UmPiAB32THIzi1IDsXlxr1lxyBZbGB/AmAjpQBwExJZh+ezR0NoeUVAu2QDRx4BNlQKnbmzmazA/6544ViT0bJjUIPTsBSsTaem3rIjEAEAHku6E2bnRrJjUEPyCQMMtnFYss2UQkt/N7g56WXHIMKlIkes8+GlO+1KaC/ZCeqMzZSCVqvhSWxkNV6M64hC37ayY1BDaR4tO0GdsZlSALizmayHSWjxjhgnOwY1CA0QFi07RJ2xqVK4JcxHdgQixfKLwbgUPFB2DKpvjTsArr6yU9QZmyqF25r7wsWRI1aS9Xjq8n0Qeg7YaNNsaNMRANjUnlmDgw69whthy4lU2VGIAACHst3xZ8sH0T15sewo+F+iEfP2lODgRRMu5Qn8ONoZ97ayPKfiZLoJ/95WjF2JRhjNQBs/LdaOckEzz4q/P0Yvy8euRFO56YNb6rHhgauXyn13TzHm/l4CAPj37Y74V08nZb4/zhvx5C9F+GOSK/RqHZageR/ZCeqUTZUCANzZOoClQFZlckJvHPDcCF3eRak58ksEOgZoMaGTA+5bXVju9tgrZvRaWoCJnR0wM9oVHk4aHE83wVDJp8QPo11QYhLK7xkFAh0/zcfINlfvdDTVhNd3FOPnB1wgBHD3twUY0EKP9gE6GM0Cj28owud3O6u3EPQGoNltslPUKZsrhb6t/aHVAGZx83mJGkJmqR4r3cfj4bzZUnMMaumAQS3L1gzKl8K07UUY3FKPuf3/2dzVwqfyLcw+zhoA/3ygf3esGC4OwMg2Vx/n1GUzOgTo0Dfs6kdNhwAtTl02o32ADvN+L0FUMz1uCVbxJt9mPQAH29o8aFP7FACgkZsTj0Iiq/N6Qhvk+XWRHeOGzEJgw1kjIny0GPh1Pvzn5eLWL/Ow7lRptZaz+HApxrRzgKvj1aJo76/FmQwTkrLNSMwy40yGGe38tYi9YsbSmFK82dfpJku0cja26QiwwVIAgH6tA2RHILIghAbTSx6GgHVuJknLF8grAd75vRh3tdBjy8MuGN7KAfetKsSuBGOVlrH/ggnH0syY1MVRmdbaT4e3+hnQf0UBBnxdgLf7GdDaT4fJPxdibn8nbI41ot3CPHT+LA//S6za41iViLtkJ6hzNrf5CAD6twnAvM2nZccgsrA2NQDPhA9D6Pn1sqOUU7a59Z5IPabedvXbe6dAHfYkm/DpwRL0Dr35R8XiQyVo769F9+s2Bz3ezRGPd/unKJbHlMDdSYPbmugQuSAPfz7qivM5AmPWFCL+WTc46a2zOMvxaw34t5Kdos7Z5JpCRIA7mvm4yI5BVM7jKUMhHN1kxyinkYsGei3Qxs/yA711Iy2Ssm++gy6/ROC746WY2LnyEWIvF5gxc1cxPh5kwB8XTIjw1aKlrw59wvQoNQNnMsy1eh4Nqp1tXpvbJksBAPq19pcdgaicU3ku2BXwiOwY5TjqNLglSIfT130on7liRojnzb+5f3+iFMVG4KEOlZfC1M3FmNrDCU08tDCZgdJrHs5oFjCp6QCRtiwFVenP/QpkpZ6Kvw2lHiEN/rh5JQIxKSbEpFw9ryA+04yYlKs7gQHgxZ6OWHWsFF8cLMG5K2Ys2F+Cn04b8eQt/2z6eeTHQryyrajcshcfLsW9rfTwdbnxR8rWWCPOZJjwVPerxXFLsA6nLpux8WwpPj9YAp1Gg0hflXwkBbYHGtnm5Vdtcp8CAHQP84GHQY+cIhXuvCKblm/U4QvnCXgyZ3qDPu6Biyb0WV6g/P78lmIAxRjb0QHL7nXG8NYO+PRugbd3l2DKpiJE+mqxdpQzejX752MiKdsMrcbyg/v0ZRN2J5mw5aEbb7ItLBV4emMRVo1whlZzdc2jiYcWHw8yYPz6IjjpgeX3GuDsoJL9CW2Hy05QbzRCCDWtsFXLtB//wjd/JMmOQVShmNAF8ErZIzsG1cSUmKvXULBBKllXq5n7uzeTHYHohl7KewBCo+ITt+xVUGebLQTAxkuhXbAn2gV7yI5BVKEtl31wpskI2TGoumx40xFg46UAAGNu4doCWa/J5wfCbPCSHYOqSqMD2tl2kdt8KdzTKYjDaZPVSig0YHOjcbJjUFVFDgI8g2WnqFc2XwruBgcMad9YdgyiG3ourhuKvSNkx6CquGWi7AT1zuZLAQDGcIczWbFisxYf6MfJjkE34xtukwPgXc8uSqFriDciAqxvaAGiMouSQ5Ee1Fd2DKpMtwmARiXnUdSCXZQCwB3OZP2mZo2E0DnefEZqeA4uQKcHZadoEHZTCvd1CYaT3m6eLqnQ7iueOBo0WnYMqki7+wBnL9kpGoTdfEp6uThiULtA2TGIKjU5qR/MLn6yY9D1bnlUdoIGYzelAABje4bKjkBUqZRiR6z1Gi87Bl0ruCsQ1El2igZjV6XQuZk3bmvuKzsGUaVeju+AwkbtZMegMj2elJ2gQdlVKQDAU31sc7hbsh0mocVb5rGyYxAA+La02esm3IjdlUKvlo3QsamX7BhElVpxMRgXggfJjkFRLwBa+/qYtK9n+7cno1vIjkB0U0+lD4fQO8uOYb98mgPtR8pO0eDsshQGtAlAZIC77BhElYrJccO+xg/JjmG/7ngB0NrfuGl2WQoajQbP3tlSdgyim3o84Q4Y3W17ADar5B0KdLDPc0bsshQAYFC7QLRuzGstkHXLLtXja7cJsmPYn17PAzqbvVpxpey2FDQaDaZybYFUYEZ8a+T6d5Mdw354NgM6PSA7hTR2WwoAMKBtIDo08ZQdg+imXit+CEJj1/9dG06v5wCdg+wU0tj9u2xqf45jT9Zvfao/4oPvkR3D9vmGA10ekZ1CKrsvhT6R/ugV3kh2DKKbevzS3RCOHAK+XvV/w67XEgCWAgBg5j1t4ajjS0HW7Uy+M3YE8EznehMWBbQaLDuFdPwkBNDCzw0TeoXJjkF0U8/E3YZST75X65xGCwyYLTuFVWAp/G1Kv3A09jTIjkFUqXyTFp86cRTVOtf5IaBxB9kprAJL4W8ujnq8NqSN7BhEN/VeUjiuBPaSHcN2GLyAfjNkp7AaLIVrDOnQGLeHc2htsn4v5o6B0NrnyVV1rs80wLVm/++HDh2Ku+66q8LbfvvtN2g0Ghw9ehQajabCn3379gEAli1bpkzTarVo3LgxRo8ejaSkJItlRkdHW9w/ICAAI0eORGJiYo3yV4SlcJ2Zw9rBQWf7F+cmdfs1wwengkfIjqF+Ae2AWybW+O4TJ07E1q1bcf78+XK3LV26FN26dYOHx9WRE7Zt24ZLly5Z/HTt2lWZ38PDA5cuXcKFCxewdu1anD59GiNHlh+Q79FHH8WlS5dw8eJFrF+/HsnJyXjoobobI4ulcJ1wf+50JnV4NHkgzM4+smOol0YLDHm/VoPe3X333fDz88OyZcsspufl5eH777/HxIn/FI6vry8CAwMtfhwc/jn8VaPRIDAwEI0bN0bPnj0xceJE7N+/Hzk5ORbLdnFxUebr0aMHnn76aRw6dKjGz+F6LIUKTOnbkjudyeqdL3LCBp9xsmOo161PAM1urdUi9Ho9HnnkESxbtgxCCGX6999/D5PJhPvvv79Gy01LS8OPP/4InU4Hne7GpXXlyhWsXr0at95au+dxLZZCBVyd9Jg2pLXsGEQ39Xx8VxT7RMqOoT6+4UC//9TJoiZMmIDY2Fjs2rVLmbZ06VL83//9Hzw9/xlGp2fPnnBzc7P4uVZ2djbc3Nzg6uqKgIAA7NixA0899RRcXV0t5lu4cKEyn6+vL06fPo0lS5bUyXMBWAo3dHeHIERH+smOQVSpUrMG72l5iGq1aLTAPQsBh7q5gFGrVq3Qs2dP5YP53Llz+O233yw2HQHAqlWrEBMTY/FzLXd3d8TExODAgQN477330KVLF8yeXf7ciQcffBAxMTE4cuQIdu/ejfDwcAwYMAC5ubl18nxYCpWYN6IjGrk5yo5BVKnPzzdDalA/2THUo8eTtd5sdL2JEydi7dq1yM3NxdKlS9GiRQv07t3bYp6mTZsiPDzc4udaWq0W4eHhaN26NZ5//nn06NEDTzzxRLnH8vT0VO5/++23Y/HixTh79ixWrVpVJ8+FpVAJP3cnzBvRUXYMopt6LnMEhM5Jdgzr59sS6Fs3m42uNWrUKGi1WqxcuRJfffUVJkyYAI2mdkcxvvzyy1i1atVNdyKX7XMoLCys1eOVYSncRJ9W/hjXM1R2DKJK7c30xOGgMbJjWDeNFrh3IeBQ9weRuLm5YfTo0XjllVdw6dIljBs3rtw8GRkZSElJsfgpKiq64TKbNm2K4cOH4/XXX7eYXlBQoNz/yJEjeOKJJ2AwGDBgwIA6eS4shSp4eVArtArkNZ3Juk1O7AuTq7/sGNbrtqeApt3rbfETJ05EZmYmBg4ciKCgoHK333nnnWjcuLHFz7p16ypd5tSpU7Fhwwbs379fmfbFF18o9+/Tpw8uX76MX375BZGRdXPAgUZcexwV3dCZ1FwM/Xg3io1m2VGIbmhO86MYffEd2TGsj39b4NHt9bKWYGu4plBFEQHueHUwD1Ml6/ZyfHsUNOLAbhacPIDRK1gIVcRSqIaxPUPRrxVXz8l6CaHBLBOvuWDhngWAbwvZKVSDpVBNc0d0gJ87j/Ig6/XdpcZIbjJEdgzr0OMpoA0vY1odLIVq8nVzwnsjO6KWR5sR1aun0u6BcHCRHUOupj2A/rNkp1AdlkINREX44Zk+4TefkUiSozlu2BtYdyNnqo5LI2DkUkDH4cWri6VQQ1P7R2BIh8ayYxDd0BMJvWB0byI7RsPTaIERiwGP8oeF0s2xFGpIo9HgvZEd0bmZl+woRBXKLtVjuesE2TEaXvSrQPNo2SlUi6VQCwYHHb54pBuCvepmYC2iuvZGQivkBNTfCVtWp+19QNQLslOoGkuhlhq5OWHJuFvg7sRtl2SdXi14CEJjB//VQ24Hhn8KHgVSO3bwTql/kYHu+PiBztBp+WYk6/NzeiPENhkuO0b9ahQBjPkG0PNw8dpiKdSR6Eh/vH53G9kxiCr0xMXBEE4esmPUD7cA4ME1gLO37CQ2gaVQh8b2DMXY20JkxyAq52y+M7b52eCZzg6uwAOrAG/+v6srLIU69vrQtrxiG1mlKfHdUeLVXHaMuqPRXT0XIaiz7CQ2haVQx3RaDRY80AXtgm10VZ1Uq9Ckw0JHGzpEdch7QMRA2SlsDkuhHrg56bFiwq28BgNZnQ+SmiOjcZTsGLUX/SrQjdemrg8shXri7eqIbybdipb+brKjEFn4V/ZoCK2KD6Hu/TIQ/W/ZKWwWS6Ee+bo54ZtHb0XzRq6yoxApdl7xxvHgUbJj1Ezvl4E+r8hOYdNYCvXM392AlY/2QIivnY9YSVZlcnJ/mJ19ZceoHhZCg2ApNIBATwNWPXYb1xjIalwocsJPPiraJs9CaDAshQYS6GnAd5N7cB8DWY0X4jujyEcFl5hlITQolkID8nc34LvHevCoJLIKpWYN5mnGyY5RORZCg2MpNDBfNyd891gPnsdAVmHxhaZICeovO0YFNED/N1gIErAUJPByccR3j93GM5/JKky58n8QeoPsGP/QOQEjlgC3T5GdxC6xFCRxc9Jj8dhbOFYSSbc/ywMHgx6QHeMqZ2/gkfVAu/tkJ7FbGiGEkB3C3i3fk4BZP5+Aycx/CpLDz7EU+9z/DV1+irwQXiFXRzv1i5CXgbimYA3G9gzFl2O78UI9JE16iQNWeUg8RDWoMzBpGwvBCnBNwYqcTsnFhGV/4kJWoewoZIc0GoFjTebBNT2mYR+45cCro5068jwea8A1BSsSGeiOdU/djs7NvGRHITskhAYzSh+BQANeQbD7ZOD+b1kIVoRrClaoqNSEF74/gp+PXpIdhezQrvDvEHL+v/X7IA6uwLCPgPYj6vdxqNpYClZKCIH5W8/g4x3nwH8hakht3fPxM56DpjS/fh6gUSQwegXgF1k/y6da4eYjK6XRaPD8gEgsH98dfu68GDk1nOO5rtgd+HD9LLzdCOCxHSwEK8Y1BRXIyCvGS2uO4tdTabKjkJ1w1xtx2Oc16HOS6maBOkdg4FtA90frZnlUb7imoAK+bk5YPO4WzLqnLZz0/Cej+pdr1GOJSx1dutOzKTB+EwtBJbimoDJnUnMx5dvDOJWSKzsK2YEjIR/BM3VfzRfQeigw9CPAxafuQlG9YimoUFGpCe9sPIVlexJkRyEbN9jvMj7JmwqNMFXvjs4+wJB3gXb/Vz/BqN6wFFRsx6k0vLjmCC7nlciOQjZsS8sfEZH8fdXv0HooMGQ+4MYBH9WIpaBy6bnFeHHNEew8nS47Ctmo5i5F+NVhKjTF2ZXP6OwNDH6X5x6oHEvBRvx89CJmbziJS9lFsqOQDfos/A8MPP/hjWdodTdw93zAzb/hQlG9YCnYkIISIz789SyW7I5HqYn/rFR3nHUmHPGbCcesc9fd4AMMmgN0GCUnGNU5loINOpeWhxn/PY7d5y7LjkI25OmmCXgh/dWrv2h0QLfxQJ9pPLLIxrAUbNiGo5fw5oYT3KREdeZA2GdopC8GBs8DGneQHYfqAUvBxhWUGPHx9nNY/Fs8Skxm2XFIxYK9nPHWkBD0bt9CdhSqRywFOxGbfnWT0m9nuUmJqsfNSY8noltgYq8wGBx0suNQPWMp2Jmdp9Pw/tYzOHr+JocXkt3TaTUYc0tTTO0fgUZuHJTRXrAU7NTWE6l4f+sZnLyUIzsKWRm9VoNhnYLwZHQ4wv3dZMehBsZSsGNCCGw6loIPtp3F6VSOpWTvDA5ajO7WFI9GNUcTbxfZcUgSlgJBCIGtJ1Lxyc5YHEnOkh2HGpi7QY9HbgvB+NvDuJmIWApk6fdzl/HJjnPYE5shOwrVs0ZuTpjYKwwP9WgGd4OD7DhkJVgKVKHDSZlYvicBG4+loNjIQ1ltSVMfZzwW1QIjuzbh0URUDkuBKpVdUIofDp/Hd/uTud9BxbQa4LYWvhh9SzMMad8YOq1GdiSyUiwFqrJDSZn4bn8Sfj56CQUl1Rxfn6QI9XXB/3Vpgvu6NkGwl7PsOKQCLAWqttyiUvz3yEV8uz8Jxy7wkFZr4+akx+D2gRjRtSm6h3FcIqoelgLVyrEL2fjuzyT8N+YicoqMsuPYLY0G6BHmixFdm2BQ+0C4OOplRyKVYilQnTCazNifcAXbTqTh11OpSMwokB3JLrRp7IGBbQNxX5dgNPXhuQVUeywFqhdnU3Ox9WQqfj2ZhsNJmTDzXVYnPAx63NHSD70j/RAd4Qd/D4PsSGRjWApU7zLyivHrqTRsO5GK3ecucyd1NbVp7IHoSD9ER/qjSzMv6HVa2ZHIhrEUqEEVlZqwNy4DBxKu4HBSFo6ez0ZeMfdFXMvDoEevlo0QHeGP6EiuDVDDYimQVGazwLn0PBxOykRMchYOJ2XhbFoeTHayvclBp0FkoDs6NfVCxyZe6NzMCy383KDR8DwCkoOlQFYnv9iIo+ezEZOchZjkTBxJzkZKjvqvHufiqENkoDvaNPZA679/2gZ58KxisiosBVKF/GIjEjLykXC5APGX8xB/uQCJGfk4n1mItNwiq9iRrdUA/u4GNPYyIMjTGUFeBjT2dEaQlzMiAtwQ6usKLc8kJivHUiDVM5rMuJRdhItZhbiQVYhL2UXILTKioMSIvGIjCopNyC8xIr/YiPxi09VpJVf/fv0lSvVaDQwOOjjptcqfjtf83eCgg8FBC393A4K8rv3gNyDAwwAH7gQmlWMpkF0rNZlRUGJSyoBjApG9YykQEZGC67pERKRgKRARkYKlQERECpYCEREpWApERKRgKRARkYKlQERECpYCEREpWApERKRgKRARkYKlQERECpYCEREpWApERKRgKRARkYKlQERECpYCEREpWApERKRgKRARkYKlQERECpYCEREpWApERKRgKRARkYKlQERECpYCEREpWApERKRgKRARkYKlQERECpYCEREpWApERKRgKRARkYKlQERECpYCEREpWApERKRgKRARkYKlQERECpYCEREpWApERKRgKRARkYKlQERECpYCEREpWApERKRgKRARkYKlQERECpYCEREpWApERKT4f7Q9yoi0GqHgAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 5: Morphological analysis\n",
        "**Q1.** Choose another language and do an analysis like the one we did for finnish, for a text of your choice in both languages.\n",
        "\n",
        "*How to start:*\n",
        "1. SpaCy provides several pre-trained language models for various languages, each equipped with a morphological analyzer. Below is a list of examples of the available languages in SpaCy, along with their features regarding morphological analysis:\n",
        "\n",
        "| Language    | Model             | Features                                                                                                  |\n",
        "|-------------|-------------------|-----------------------------------------------------------------------------------------------------------|\n",
        "| English     | `en_core_web_sm`  | POS tagging, lemmatization, dependency parsing, named entity recognition.                                 |\n",
        "| German      | `de_core_news_md` | Strong morphological analysis due to complex inflections, including case and gender handling.             |\n",
        "| Spanish     | `es_core_news_md` | Handles various verb conjugations, gendered nouns, and includes lemmatization.                            |\n",
        "| French      | `fr_core_news_sm` | Supports conjugation of verbs, gendered nouns, and includes detailed morphological annotations.           |\n",
        "| Italian     | `it_core_news_sm` | Handles noun and verb inflections, gender, and number, with strong morphological features.                |\n",
        "| Dutch       | `nl_core_news_sm` | Provides morphological features for Dutch nouns and verbs, including inflection handling.                 |\n",
        "| Portuguese  | `pt_core_news_sm` | Handles noun gender and number, as well as verb conjugation.                                              |\n",
        "| Russian     | `ru_core_news_sm` | Supports rich morphological features due to the inflectional nature of Russian, including case and aspect.|\n",
        "| Turkish     | `tr_core_news_sm` | Handles agglutination, allowing for complex morphological structures.                                     |\n",
        "| Chinese     | `zh_core_web_sm`  | Tokenization and basic morphological analysis, given the language’s unique structure.                    |\n",
        "| Czech       | `cs_core_news_sm` | Handles case, gender, and number in nouns and verbs.                                                     |\n",
        "\n",
        "**if you run intro troubles while loading the models, go to [spacy](https://spacy.io/models/) and use the search tool in the website to look for the model in the language you are interested in.**\n",
        "\n",
        "2.  Like you did at the end of Lab 1, upload a text for you to analyze.\n",
        "A good text for morphological analysis should ideally contain a variety of words with rich inflectional and derivational morphology, as this will allow you to see how morphology affects the structure and meaning of words. For this exercise, choose a text of at most 750 words and perhaps no less than 250.\n",
        "\n",
        "3. Translate the text into the other language and upload it into a second file (if the text is in Finnish, translate it to the language of your choice, and viceversa). You can do this yourself, find a translated version online or use a web tool for translation\n",
        "\n",
        "4. you need to segment your texts it to be able to pass it to the SpaCy model.\n"
      ],
      "metadata": {
        "id": "z2o4ALVsuJ_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remember to download the model you want. something like:\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download zh_core_web_sm\n",
        "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl\n",
        "\n",
        "# !pip install https://github.com/explosion/spacy-models/releases/download/zh_core_web_sm-3.7.1/zh_core_web_sm-3.7.1-py3-none-any.whl\n",
        "\n",
        "# !python -m spacy download es_core_web_md"
      ],
      "metadata": {
        "id": "uhPEOUms2Ffk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70fef2b8-385c-4a2b-e419-74bb9a5f1b02"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting zh-core-web-sm==3.7.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/zh_core_web_sm-3.7.0/zh_core_web_sm-3.7.0-py3-none-any.whl (48.5 MB)\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from zh-core-web-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-pkuseg<0.1.0,>=0.0.27 in /usr/local/lib/python3.10/dist-packages (from zh-core-web-sm==3.7.0) (0.0.33)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (0.4.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (1.2.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('zh_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here ... this is just a template to get you started\n",
        "import spacy\n",
        "\n",
        "# Load SpaCy models for the chosen languages\n",
        "nlp_lang1 = spacy.load(\"en_core_web_sm\")  # English model as an example\n",
        "nlp_lang2 = spacy.load(\"zh_core_web_md\")  # chinese model as an example\n",
        "\n",
        "# Sample texts in the two languages... you need to load your both texts here:\n",
        "text_lang1 = \"The quick brown fox jumps over the lazy dog.\"\n",
        "text_lang2 = \"为解决在多场景（跨域、长时以及噪声干扰语音场景）下说话人确认系统性能较差的问题，提出了一种基于Conformer构建的、实时多场景鲁棒的说话人识别模型——PMS-Conformer。PMS-Conformer的设计灵感来自于先进的模型 MFA-Conformer。PMS-Conformer 对 MFA-Conformer 的声学特征提取器、网络组件和损失函数计算模块进行了改进，其具有新颖有效的声学特征提取器，以及鲁棒的、具有较强泛化能力的声纹嵌入码提取器。基于VoxCeleb1&2数据集实现了PMS-Conformer的训练；开展了PMS-Conformer与基线MFA-Conformer以及ECAPA-TDNN在说话人确认任务上的性能对比评估实验。实验结果表明在长语音SITW、跨域VoxMovies以及加噪处理的VoxCeleb-O测试集上，以PMS-Conformer构建的说话人确认系统的性能比用这两个基线构建的说话人确认系统更有竞争力；并且在声纹嵌入码提取器的可训练参数（Params）和推理速度（RTF）方面，PMS-Conformer 明显优于 ECAPA-TDNN。实验结果说明了PMS-Conformer在实时多场景下具有良好的性能。\"\n"
      ],
      "metadata": {
        "id": "6ra7xXYRt3St"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.** Write a short reflection answering the following questions:\n",
        "\n",
        "- How does morphology shape the structure and meaning of sentences in each language?\n",
        "- What challenges did you observe in analyzing morphology in one language versus the other?\n",
        "- What insights did you gain about the nature of language through this morphological comparison?\n",
        "\n",
        "\n",
        "**Expected Outputs for Q1 and Q2:**\n",
        "- Analysis Tables for each language, showing token, lemma, POS tag, and morphological features.\n",
        "- Visualization to compare morphological feature distributions.\n",
        "- Written Reflection answering the questions above."
      ],
      "metadata": {
        "id": "wy9tB4V8x_MY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_Chinese_words(text_lang2):\n",
        "    analysis_results = []\n",
        "\n",
        "    doc = nlp_lang2(text_lang2)\n",
        "\n",
        "    for token in doc:\n",
        "      analysis_results.append({\n",
        "                  'original_word': token.text,\n",
        "                  'lemma': token.lemma_,\n",
        "                  'part_of_speech': token.pos_,\n",
        "                  'morphological_features': token.morph,\n",
        "            })\n",
        "\n",
        "    return analysis_results\n",
        "\n",
        "# Run the morphological analysis\n",
        "results2 = analyze_Chinese_words(text_lang2)\n",
        "\n",
        "# Display the results\n",
        "for result in results2:\n",
        "    print(f\"Original Word: {result['original_word']}\")\n",
        "    print(f\"Lemma: {result['lemma']}\")\n",
        "    print(f\"Part of Speech: {result['part_of_speech']}\")\n",
        "    print(f\"Morphological Features: {result['morphological_features']}\")\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "id": "-vrskkrf2kSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2fb791-4a00-4f29-9d04-895a150e5d22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Word: 为\n",
            "Lemma: \n",
            "Part of Speech: ADP\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 解决\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 在\n",
            "Lemma: \n",
            "Part of Speech: ADP\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 多\n",
            "Lemma: \n",
            "Part of Speech: NUM\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 场景\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: （\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 跨域\n",
            "Lemma: \n",
            "Part of Speech: ADJ\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 、\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 长时\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 以及\n",
            "Lemma: \n",
            "Part of Speech: CCONJ\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 噪声\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 干扰\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 语音\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 场景\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: ）\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 下\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 说话人\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 确认\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 系统\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 性能\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 较\n",
            "Lemma: \n",
            "Part of Speech: ADV\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 差\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 问题\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: ，\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 提出\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 了\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 一\n",
            "Lemma: \n",
            "Part of Speech: NUM\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 种\n",
            "Lemma: \n",
            "Part of Speech: NUM\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 基于\n",
            "Lemma: \n",
            "Part of Speech: ADP\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Conformer\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 构建\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 、\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 实时\n",
            "Lemma: \n",
            "Part of Speech: ADV\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 多\n",
            "Lemma: \n",
            "Part of Speech: NUM\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 场景\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 鲁棒\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 说话\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 人\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 识别\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 模型\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: ——\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: PMS\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Conformer\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 。\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: PM\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: S\n",
            "Lemma: \n",
            "Part of Speech: X\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Conformer\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 设计\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 灵感\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 来自于\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 先进\n",
            "Lemma: \n",
            "Part of Speech: ADJ\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 模型\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: MFA\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Conformer\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 。\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: PM\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: S\n",
            "Lemma: \n",
            "Part of Speech: X\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Conformer\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 对\n",
            "Lemma: \n",
            "Part of Speech: ADP\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: MFA\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Conformer\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 声学\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 特征\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 提取器\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 、\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 网络\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 组件\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 和\n",
            "Lemma: \n",
            "Part of Speech: CCONJ\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 损失\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 函数\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 计算\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 模块\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 进行\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 了\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 改进\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: ，\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 其\n",
            "Lemma: \n",
            "Part of Speech: PRON\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 具有\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 新颖\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 有效\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 声学\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 特征\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 提取器\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: ，\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 以及\n",
            "Lemma: \n",
            "Part of Speech: CCONJ\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 鲁棒\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 、\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 具有\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 较\n",
            "Lemma: \n",
            "Part of Speech: ADV\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 强\n",
            "Lemma: \n",
            "Part of Speech: ADJ\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 泛化\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 能力\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 声纹\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 嵌入\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 码\n",
            "Lemma: \n",
            "Part of Speech: NUM\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 提取器\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 。\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 基于\n",
            "Lemma: \n",
            "Part of Speech: ADP\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: VoxCeleb\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 1\n",
            "Lemma: \n",
            "Part of Speech: NUM\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: &\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 2\n",
            "Lemma: \n",
            "Part of Speech: NUM\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 数据集\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 实现\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 了\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: PMS\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Conformer\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 训练\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: ；\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 开展\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 了\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: PMS\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Conformer\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 与\n",
            "Lemma: \n",
            "Part of Speech: CCONJ\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 基线\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: MFA\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Conformer\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 以及\n",
            "Lemma: \n",
            "Part of Speech: CCONJ\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: ECAPA\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: TDNN\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 在\n",
            "Lemma: \n",
            "Part of Speech: ADP\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 说话\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 人\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 确认\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 任务\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 上\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 性能\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 对比\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 评估\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 实验\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 。\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 实验\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 结果\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 表明\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 在\n",
            "Lemma: \n",
            "Part of Speech: ADP\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 长语\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 音\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: SITW\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 、\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 跨域\n",
            "Lemma: \n",
            "Part of Speech: ADJ\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Vox\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Movies\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 以及\n",
            "Lemma: \n",
            "Part of Speech: CCONJ\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 加噪\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 处理\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: VoxCeleb\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: DET\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: O测\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 试集\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 上\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: ，\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 以\n",
            "Lemma: \n",
            "Part of Speech: ADP\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: PMS\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Conformer\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 构建\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 说话\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 人\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 确认\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 系统\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 性能\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 比\n",
            "Lemma: \n",
            "Part of Speech: ADP\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 用\n",
            "Lemma: \n",
            "Part of Speech: ADP\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 这\n",
            "Lemma: \n",
            "Part of Speech: DET\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 两\n",
            "Lemma: \n",
            "Part of Speech: NUM\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 个\n",
            "Lemma: \n",
            "Part of Speech: NUM\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 基线\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 构建\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 说话\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 人\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 确认\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 系统\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 更\n",
            "Lemma: \n",
            "Part of Speech: ADV\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 有\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 竞争力\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: ；\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 并且\n",
            "Lemma: \n",
            "Part of Speech: ADV\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 在\n",
            "Lemma: \n",
            "Part of Speech: ADP\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 声纹\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 嵌入\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 码\n",
            "Lemma: \n",
            "Part of Speech: NUM\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 提取器\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 可\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 训练\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 参数\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: （\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Params\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: ）\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 和\n",
            "Lemma: \n",
            "Part of Speech: CCONJ\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 推理\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 速度\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: （\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: RTF\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: ）\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 方面\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: ，\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: PMS\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Conformer\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 明显\n",
            "Lemma: \n",
            "Part of Speech: ADV\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 优于\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: ECAPA\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: TDNN\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 。\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 实验\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 结果\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 说明\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 了\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: PMS\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: -\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: Conformer\n",
            "Lemma: \n",
            "Part of Speech: PROPN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 在\n",
            "Lemma: \n",
            "Part of Speech: ADP\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 实时\n",
            "Lemma: \n",
            "Part of Speech: ADV\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 多\n",
            "Lemma: \n",
            "Part of Speech: NUM\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 场景\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 下\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 具有\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 良好\n",
            "Lemma: \n",
            "Part of Speech: VERB\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 的\n",
            "Lemma: \n",
            "Part of Speech: PART\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 性能\n",
            "Lemma: \n",
            "Part of Speech: NOUN\n",
            "Morphological Features: \n",
            "---\n",
            "Original Word: 。\n",
            "Lemma: \n",
            "Part of Speech: PUNCT\n",
            "Morphological Features: \n",
            "---\n"
          ]
        }
      ]
    }
  ]
}